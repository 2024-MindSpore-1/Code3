{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PDE-Net 2.0 for 2D Burgers Equation\n",
    "## —— pretrain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "PDE-Net 2.0, also named Poly PDE-Net, introduces some improvements on the basis of PDE-Net including a symbolic neural network and pseudo-upwind techniques.\n",
    "More details can be found in https://arxiv.org/pdf/1812.04426.pdf.\n",
    "\n",
    "This work constructs PDE-Net 2.0 by Mindspore 1.10.1 for solving 2D burgers equations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem Description\n",
    "This case solves the inverse problem of 2d burgers partial differential equations with variable parameters and realizes long-term prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2D Burgers Equation\n",
    "$$\n",
    "u_t = -uu_x +  vu_y + viscosity * u_{xx} + viscosity * u_{yy}, \\quad (x,y) \\in[0,2 \\pi] \\times[0,2 \\pi]\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_t = -vv_y +  uv_x + viscosity * v_{xx} + viscosity * v_{yy}, \\quad (x,y) \\in[0,2 \\pi] \\times[0,2 \\pi]\n",
    "$$\n",
    "\n",
    "$$\n",
    "u|_{t=0} = u_0(x,y), v|_{t=0} = v_0(x,y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Boundary: periodic.\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model structure\n",
    "Same as PDE-Net, PDE-Net 2.0 consists of a series of $\\delta T$ blocks sharing parameters. The shared parameters include trainable moment matrices, each of which corresponds to a convolutional kernel responsible for a specific spatial difference order.\n",
    "On the basis of PDE-Net, PDE-Net 2.0 introduces symbolic network to aggregate outputs of different convolutional kernels. Furthermore, a method named pseudo-upwind is utilized to obtain stable prediction.\n",
    "\n",
    "![block](images/poly_pdenet_block.png)\n",
    "\n",
    "![symbolic](images/poly_pdenet_symbolic.png)\n",
    "\n",
    "![poly_pdenet](images/poly_pdenet.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Technical roadmap\n",
    "We solve the problem described above as follows:\n",
    "    1. Model construction.\n",
    "    2. Warmup training.\n",
    "    3. Multistep training\n",
    "    4. Test and Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:47:55.699007Z",
     "start_time": "2023-09-09T02:47:52.870911Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "from mindspore import nn\n",
    "from mindspore.amp import all_finite\n",
    "from src.dataset import DataGenerator\n",
    "from src.pdenet import PDENetWithLoss, PolyPDENet2D\n",
    "from src.utils import init_env, get_config, init_model, load_param_dict, mkdir, generate_train_data\n",
    "from src.utils import test, evaluate\n",
    "from mindspore.train.serialization import load_param_into_net"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training environment settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ms.set_seed(1999)\n",
    "np.random.seed(1999)\n",
    "my_config = get_config('config.yaml')\n",
    "my_config['device_target'] = 'CPU'\n",
    "mkdir(config=my_config)\n",
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=my_config['device_target'], device_id=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:47:55.716977100Z",
     "start_time": "2023-09-09T02:47:55.701995400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model construction\n",
    "PDENet 2.0 is defined in class PolyPDENet2D. You need to specify the time-step, mesh width, mesh height, kernel size, highest order of kernels, number of symbolic network 's hidden layers, initial range of symbolic network's parameters, and whether using pseudo-upwind method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def init_model(config):\n",
    "    pde_net = PolyPDENet2D(dt=config['dt'], dx=config['dx'], kernel_size=config['kernel_size'],\n",
    "                           symnet_hidden_num=config['symnet_hidden_num'], symnet_init_range=config['symnet_init_range'],\n",
    "                           max_order=config['max_order'], if_upwind=config['if_upwind'], dtype=ms.float32)\n",
    "    return pde_net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:47:55.759969800Z",
     "start_time": "2023-09-09T02:47:55.717985400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define single step training\n",
    "The model is trained with increasing steps. The moment matrices are not updated during warmup phase at which step equals 1. While step is larger than 1, the moment matrices are normally updated. Each time a $\\delta T$ block is added, the program generates data and reads data sets. After the model initialized, the program loads the checkpoint trained in the previous step, defines the optimizer, mode, and loss function. During training process, the performance of model is evaluated and the equivalent expression of model is shown periodically."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def single_train(step_num: int, config: dict, data_generator: DataGenerator):\n",
    "    # generate data: (data_num, step_num + 1, 2, sample_mesh_size_y, sample_mesh_size_x)\n",
    "    train_dataset = generate_train_data(config=config, data_generator=data_generator)\n",
    "    pde_net = init_model(config=config)\n",
    "    if step_num == 1:\n",
    "        # warm up\n",
    "        regularization = False\n",
    "        frozen = True\n",
    "        pde_net.set_frozen(frozen=frozen)\n",
    "        epochs = config['warmup_epochs']\n",
    "        lr = config['warmup_lr']\n",
    "    else:\n",
    "        if step_num == 2:\n",
    "            load_epoch = config['warmup_epochs']\n",
    "        else:\n",
    "            load_epoch = config['epochs']\n",
    "\n",
    "        param_dict = load_param_dict(save_directory=config['save_directory'], step=step_num - 1, epoch=load_epoch)\n",
    "        param_not_load = load_param_into_net(net=pde_net, parameter_dict=param_dict)\n",
    "        print('=============== Net saved at last step is loaded. ===============')\n",
    "        print('!!!!!!!!! param not loaded: ', param_not_load)\n",
    "\n",
    "        regularization = True\n",
    "        frozen = False\n",
    "        pde_net.set_frozen(frozen=frozen)\n",
    "        epochs = config['epochs']\n",
    "        lr = config['lr'] * np.power(config['lr_reduce_gamma'], (step_num - 1) // config['lr_reduce_interval'])\n",
    "\n",
    "    # lr scheduler\n",
    "    my_optimizer = nn.Adam(params=pde_net.trainable_params(), learning_rate=lr)\n",
    "    net_with_loss = PDENetWithLoss(pde_net=pde_net,\n",
    "                                   moment_loss_threshold=config['moment_loss_threshold'],\n",
    "                                   symnet_loss_threshold=config['symnet_loss_threshold'],\n",
    "                                   moment_loss_scale=config['moment_loss_scale'],\n",
    "                                   symnet_loss_scale=config['symnet_loss_scale'],\n",
    "                                   step_num=step_num, regularization=regularization)\n",
    "\n",
    "    def forward_fn(trajectory):\n",
    "        loss = net_with_loss.get_loss(batch_trajectory=trajectory)\n",
    "        return loss\n",
    "    value_and_grad = ms.ops.value_and_grad(forward_fn, None, weights=my_optimizer.parameters)\n",
    "\n",
    "    def train_process(trajectory):\n",
    "        # TNCHW\n",
    "        trajectory = ms.numpy.swapaxes(trajectory, 0, 1)\n",
    "        loss, grads = value_and_grad(trajectory)\n",
    "        if config['device_target'].upper() == 'ASCEND':\n",
    "            status = ms.numpy.zeros((8, ))\n",
    "        else:\n",
    "            status = None\n",
    "        if all_finite(grads, status=status):\n",
    "            my_optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "    for epoch_idx in range(1, epochs + 1):\n",
    "        pde_net.set_train(mode=True)\n",
    "        avg_loss = 0\n",
    "        for batch_trajectory in train_dataset.fetch():\n",
    "            train_loss = train_process(batch_trajectory)\n",
    "            avg_loss += train_loss.asnumpy()\n",
    "        print('step_num: {} -- epoch: {} -- lr: {} -- loss: {}'.format(step_num, epoch_idx,\n",
    "                                                                       my_optimizer.learning_rate.value(),\n",
    "                                                                       avg_loss))\n",
    "        # generate new data\n",
    "        if epoch_idx % config['generate_data_interval'] == 0:\n",
    "            train_dataset = generate_train_data(config=config, data_generator=data_generator)\n",
    "        # evaluate\n",
    "        if epoch_idx % config['evaluate_interval'] == 0:\n",
    "            evaluate_error = evaluate(model=pde_net, data_generator=data_generator, config=config, step_num=step_num)\n",
    "            print('=============== Max evaluate error: {} ==============='.format(evaluate_error))\n",
    "            print('=============== Current Expression ===============')\n",
    "            pde_net.show_expression(coe_threshold=config['coe_threshold'])\n",
    "\n",
    "        if epoch_idx == epochs:\n",
    "            print('=============== Current Expression ===============')\n",
    "            pde_net.show_expression(coe_threshold=config['coe_threshold'])\n",
    "            pde_net.show_kernels()\n",
    "            save_path = os.path.join(config['save_directory'],\n",
    "                                     'pde_net_step{}_epoch{}.ckpt'.format(step_num, epoch_idx))\n",
    "            ms.save_checkpoint(pde_net, save_path)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:47:55.775990Z",
     "start_time": "2023-09-09T02:47:55.732060900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warmup training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def pretrain(config):\n",
    "    data_generator = DataGenerator(config=config)\n",
    "    single_train(config=config, step_num=1, data_generator=data_generator)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T02:47:55.775990Z",
     "start_time": "2023-09-09T02:47:55.760974Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1 -- lr: 0.001 -- loss: 26.776227951049805\n",
      "step_num: 1 -- epoch: 2 -- lr: 0.001 -- loss: 26.633957386016846\n",
      "step_num: 1 -- epoch: 3 -- lr: 0.001 -- loss: 26.502192497253418\n",
      "step_num: 1 -- epoch: 4 -- lr: 0.001 -- loss: 26.375828742980957\n",
      "step_num: 1 -- epoch: 5 -- lr: 0.001 -- loss: 26.273977279663086\n",
      "step_num: 1 -- epoch: 6 -- lr: 0.001 -- loss: 26.165760040283203\n",
      "step_num: 1 -- epoch: 7 -- lr: 0.001 -- loss: 26.068905353546143\n",
      "step_num: 1 -- epoch: 8 -- lr: 0.001 -- loss: 25.981074810028076\n",
      "step_num: 1 -- epoch: 9 -- lr: 0.001 -- loss: 25.893912315368652\n",
      "step_num: 1 -- epoch: 10 -- lr: 0.001 -- loss: 25.81773567199707\n",
      "step_num: 1 -- epoch: 11 -- lr: 0.001 -- loss: 25.738539695739746\n",
      "step_num: 1 -- epoch: 12 -- lr: 0.001 -- loss: 25.66281223297119\n",
      "step_num: 1 -- epoch: 13 -- lr: 0.001 -- loss: 25.60450839996338\n",
      "step_num: 1 -- epoch: 14 -- lr: 0.001 -- loss: 25.535609245300293\n",
      "step_num: 1 -- epoch: 15 -- lr: 0.001 -- loss: 25.466763496398926\n",
      "step_num: 1 -- epoch: 16 -- lr: 0.001 -- loss: 25.400475025177002\n",
      "step_num: 1 -- epoch: 17 -- lr: 0.001 -- loss: 25.344119548797607\n",
      "step_num: 1 -- epoch: 18 -- lr: 0.001 -- loss: 25.279158115386963\n",
      "step_num: 1 -- epoch: 19 -- lr: 0.001 -- loss: 25.211379051208496\n",
      "step_num: 1 -- epoch: 20 -- lr: 0.001 -- loss: 25.15040683746338\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 21 -- lr: 0.001 -- loss: 28.202824592590332\n",
      "step_num: 1 -- epoch: 22 -- lr: 0.001 -- loss: 28.157973289489746\n",
      "step_num: 1 -- epoch: 23 -- lr: 0.001 -- loss: 28.10378932952881\n",
      "step_num: 1 -- epoch: 24 -- lr: 0.001 -- loss: 28.05005645751953\n",
      "step_num: 1 -- epoch: 25 -- lr: 0.001 -- loss: 27.983494758605957\n",
      "step_num: 1 -- epoch: 26 -- lr: 0.001 -- loss: 27.915507316589355\n",
      "step_num: 1 -- epoch: 27 -- lr: 0.001 -- loss: 27.849230766296387\n",
      "step_num: 1 -- epoch: 28 -- lr: 0.001 -- loss: 27.774788856506348\n",
      "step_num: 1 -- epoch: 29 -- lr: 0.001 -- loss: 27.69785785675049\n",
      "step_num: 1 -- epoch: 30 -- lr: 0.001 -- loss: 27.61750364303589\n",
      "step_num: 1 -- epoch: 31 -- lr: 0.001 -- loss: 27.533035278320312\n",
      "step_num: 1 -- epoch: 32 -- lr: 0.001 -- loss: 27.437061309814453\n",
      "step_num: 1 -- epoch: 33 -- lr: 0.001 -- loss: 27.336437225341797\n",
      "step_num: 1 -- epoch: 34 -- lr: 0.001 -- loss: 27.232943534851074\n",
      "step_num: 1 -- epoch: 35 -- lr: 0.001 -- loss: 27.11673879623413\n",
      "step_num: 1 -- epoch: 36 -- lr: 0.001 -- loss: 26.99057960510254\n",
      "step_num: 1 -- epoch: 37 -- lr: 0.001 -- loss: 26.858827114105225\n",
      "step_num: 1 -- epoch: 38 -- lr: 0.001 -- loss: 26.7132568359375\n",
      "step_num: 1 -- epoch: 39 -- lr: 0.001 -- loss: 26.569618225097656\n",
      "step_num: 1 -- epoch: 40 -- lr: 0.001 -- loss: 26.40340805053711\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 41 -- lr: 0.001 -- loss: 26.3797664642334\n",
      "step_num: 1 -- epoch: 42 -- lr: 0.001 -- loss: 26.19223642349243\n",
      "step_num: 1 -- epoch: 43 -- lr: 0.001 -- loss: 25.993831157684326\n",
      "step_num: 1 -- epoch: 44 -- lr: 0.001 -- loss: 25.768339157104492\n",
      "step_num: 1 -- epoch: 45 -- lr: 0.001 -- loss: 25.558632850646973\n",
      "step_num: 1 -- epoch: 46 -- lr: 0.001 -- loss: 25.308339595794678\n",
      "step_num: 1 -- epoch: 47 -- lr: 0.001 -- loss: 25.0750093460083\n",
      "step_num: 1 -- epoch: 48 -- lr: 0.001 -- loss: 24.812898635864258\n",
      "step_num: 1 -- epoch: 49 -- lr: 0.001 -- loss: 24.573020458221436\n",
      "step_num: 1 -- epoch: 50 -- lr: 0.001 -- loss: 24.287283897399902\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.020937398 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -0.0452718*u_x0_y0*u_x1_y0 + 0.0415458*u_x0_y0*v_x0_y0 - 0.00520397*u_x0_y0*v_x2_y0 - 0.03513*u_x0_y0 + 0.0452746*u_x0_y1*u_x1_y0 - 0.0414666*u_x0_y1*v_x0_y0 + 0.00530399*u_x0_y1*v_x2_y0 + 0.049735*u_x0_y1 + 0.0191222*u_x0_y2*u_x1_y0 - 0.0174254*u_x0_y2*v_x0_y0 + 0.0573622*u_x0_y2 + 0.0185301*u_x1_y0*u_x2_y0 + 0.00829429*u_x1_y0*v_x0_y1 - 0.0076116*u_x1_y0*v_x1_y0 - 0.0531275*u_x1_y0 - 0.0101482*u_x1_y1 - 0.0169486*u_x2_y0*v_x0_y0 + 0.0619905*u_x2_y0 - 0.0076813*v_x0_y0*v_x0_y1 + 0.00713769*v_x0_y0*v_x1_y0 - 0.0091359*v_x0_y0 + 0.0161244*v_x0_y1 - 0.01858*v_x1_y0 + 0.0109721*v_x2_y0 + 0.0289497\n",
      "derivative of v:  0.0214614*u_x0_y0**2 - 0.0136899*u_x0_y0*u_x0_y2 - 0.00527294*u_x0_y0*u_x1_y0 - 0.0145694*u_x0_y0*u_x2_y0 - 0.00589979*u_x0_y0*v_x0_y0 + 0.00609262*u_x0_y0*v_x0_y1 - 0.0456131*u_x0_y0*v_x1_y0 + 0.00891997*u_x0_y0 + 0.0157621*u_x0_y1 + 0.0167833*u_x0_y2*v_x1_y0 - 0.0059847*u_x0_y2 + 0.0117147*u_x1_y0*v_x0_y0 - 0.0114518*u_x1_y0*v_x0_y1 + 0.00567205*u_x1_y0*v_x1_y0 - 0.0155978*u_x1_y0 + 0.0090993*u_x1_y1 + 0.0175594*u_x2_y0*v_x1_y0 - 0.0121452*u_x2_y0 + 0.0239983*v_x0_y0**2 - 0.0476071*v_x0_y0*v_x0_y1 - 0.0154258*v_x0_y0*v_x0_y2 + 0.00535709*v_x0_y0*v_x1_y0 - 0.013273*v_x0_y0*v_x2_y0 - 0.020882*v_x0_y0 + 0.0232527*v_x0_y1**2 + 0.0173697*v_x0_y1*v_x0_y2 - 0.00619337*v_x0_y1*v_x1_y0 + 0.0150621*v_x0_y1*v_x2_y0 + 0.0451065*v_x0_y1 + 0.0589361*v_x0_y2 + 0.0238216*v_x1_y0**2 - 0.0457025*v_x1_y0 - 0.0137792*v_x1_y1 + 0.0574983*v_x2_y0 - 0.154555\n",
      "step_num: 1 -- epoch: 51 -- lr: 0.001 -- loss: 24.033297538757324\n",
      "step_num: 1 -- epoch: 52 -- lr: 0.001 -- loss: 23.766640663146973\n",
      "step_num: 1 -- epoch: 53 -- lr: 0.001 -- loss: 23.525297164916992\n",
      "step_num: 1 -- epoch: 54 -- lr: 0.001 -- loss: 23.262550830841064\n",
      "step_num: 1 -- epoch: 55 -- lr: 0.001 -- loss: 23.020472049713135\n",
      "step_num: 1 -- epoch: 56 -- lr: 0.001 -- loss: 22.788085460662842\n",
      "step_num: 1 -- epoch: 57 -- lr: 0.001 -- loss: 22.54350996017456\n",
      "step_num: 1 -- epoch: 58 -- lr: 0.001 -- loss: 22.31502914428711\n",
      "step_num: 1 -- epoch: 59 -- lr: 0.001 -- loss: 22.0808048248291\n",
      "step_num: 1 -- epoch: 60 -- lr: 0.001 -- loss: 21.857698440551758\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 61 -- lr: 0.001 -- loss: 24.631814002990723\n",
      "step_num: 1 -- epoch: 62 -- lr: 0.001 -- loss: 24.400880813598633\n",
      "step_num: 1 -- epoch: 63 -- lr: 0.001 -- loss: 24.1691312789917\n",
      "step_num: 1 -- epoch: 64 -- lr: 0.001 -- loss: 23.912084579467773\n",
      "step_num: 1 -- epoch: 65 -- lr: 0.001 -- loss: 23.648776054382324\n",
      "step_num: 1 -- epoch: 66 -- lr: 0.001 -- loss: 23.379821300506592\n",
      "step_num: 1 -- epoch: 67 -- lr: 0.001 -- loss: 23.115209579467773\n",
      "step_num: 1 -- epoch: 68 -- lr: 0.001 -- loss: 22.83571767807007\n",
      "step_num: 1 -- epoch: 69 -- lr: 0.001 -- loss: 22.567142963409424\n",
      "step_num: 1 -- epoch: 70 -- lr: 0.001 -- loss: 22.299193382263184\n",
      "step_num: 1 -- epoch: 71 -- lr: 0.001 -- loss: 22.03513479232788\n",
      "step_num: 1 -- epoch: 72 -- lr: 0.001 -- loss: 21.780908584594727\n",
      "step_num: 1 -- epoch: 73 -- lr: 0.001 -- loss: 21.5147442817688\n",
      "step_num: 1 -- epoch: 74 -- lr: 0.001 -- loss: 21.247960090637207\n",
      "step_num: 1 -- epoch: 75 -- lr: 0.001 -- loss: 21.002553462982178\n",
      "step_num: 1 -- epoch: 76 -- lr: 0.001 -- loss: 20.760480403900146\n",
      "step_num: 1 -- epoch: 77 -- lr: 0.001 -- loss: 20.52785301208496\n",
      "step_num: 1 -- epoch: 78 -- lr: 0.001 -- loss: 20.30315351486206\n",
      "step_num: 1 -- epoch: 79 -- lr: 0.001 -- loss: 20.07707452774048\n",
      "step_num: 1 -- epoch: 80 -- lr: 0.001 -- loss: 19.880202293395996\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 81 -- lr: 0.001 -- loss: 19.49176263809204\n",
      "step_num: 1 -- epoch: 82 -- lr: 0.001 -- loss: 19.264657020568848\n",
      "step_num: 1 -- epoch: 83 -- lr: 0.001 -- loss: 19.03011178970337\n",
      "step_num: 1 -- epoch: 84 -- lr: 0.001 -- loss: 18.767203330993652\n",
      "step_num: 1 -- epoch: 85 -- lr: 0.001 -- loss: 18.48397397994995\n",
      "step_num: 1 -- epoch: 86 -- lr: 0.001 -- loss: 18.256970405578613\n",
      "step_num: 1 -- epoch: 87 -- lr: 0.001 -- loss: 17.98477077484131\n",
      "step_num: 1 -- epoch: 88 -- lr: 0.001 -- loss: 17.780904293060303\n",
      "step_num: 1 -- epoch: 89 -- lr: 0.001 -- loss: 17.53858232498169\n",
      "step_num: 1 -- epoch: 90 -- lr: 0.001 -- loss: 17.329075813293457\n",
      "step_num: 1 -- epoch: 91 -- lr: 0.001 -- loss: 17.12373971939087\n",
      "step_num: 1 -- epoch: 92 -- lr: 0.001 -- loss: 16.911508083343506\n",
      "step_num: 1 -- epoch: 93 -- lr: 0.001 -- loss: 16.72941017150879\n",
      "step_num: 1 -- epoch: 94 -- lr: 0.001 -- loss: 16.524269104003906\n",
      "step_num: 1 -- epoch: 95 -- lr: 0.001 -- loss: 16.339293479919434\n",
      "step_num: 1 -- epoch: 96 -- lr: 0.001 -- loss: 16.170875549316406\n",
      "step_num: 1 -- epoch: 97 -- lr: 0.001 -- loss: 16.0028715133667\n",
      "step_num: 1 -- epoch: 98 -- lr: 0.001 -- loss: 15.830514907836914\n",
      "step_num: 1 -- epoch: 99 -- lr: 0.001 -- loss: 15.671527862548828\n",
      "step_num: 1 -- epoch: 100 -- lr: 0.001 -- loss: 15.507416248321533\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.016860908 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.00706667*u_x0_y0**2*u_x0_y1*u_x1_y0 - 0.00735003*u_x0_y0**2*u_x0_y1*v_x0_y0 - 0.00784014*u_x0_y0**2*u_x0_y1 + 0.00709343*u_x0_y0**2*u_x1_y0*v_x0_y0 + 0.0179652*u_x0_y0**2 - 0.00667318*u_x0_y0*u_x0_y1**2*u_x1_y0 + 0.00702956*u_x0_y0*u_x0_y1**2*v_x0_y0 + 0.0104216*u_x0_y0*u_x0_y1**2 + 0.0064795*u_x0_y0*u_x0_y1*u_x1_y0**2 - 0.0136083*u_x0_y0*u_x0_y1*u_x1_y0*v_x0_y0 - 0.0059139*u_x0_y0*u_x0_y1*u_x1_y0 + 0.00705346*u_x0_y0*u_x0_y1*v_x0_y0**2 + 0.0108487*u_x0_y0*u_x0_y1*v_x0_y0 - 0.0252369*u_x0_y0*u_x0_y1 + 0.00658119*u_x0_y0*u_x1_y0**2*v_x0_y0 - 0.0068019*u_x0_y0*u_x1_y0*v_x0_y0**2 - 0.324763*u_x0_y0*u_x1_y0 - 0.00519454*u_x0_y0*u_x2_y0 + 0.321707*u_x0_y0*v_x0_y0 - 0.0157671*u_x0_y0*v_x2_y0 - 0.0247412*u_x0_y0 + 0.00644547*u_x0_y1**2*u_x1_y0*v_x0_y0 + 0.00547797*u_x0_y1**2*u_x1_y0 - 0.00810993*u_x0_y1**2*v_x0_y0 + 0.00686812*u_x0_y1**2 - 0.00625353*u_x0_y1*u_x1_y0**2*v_x0_y0 + 0.006546*u_x0_y1*u_x1_y0*v_x0_y0**2 + 0.297549*u_x0_y1*u_x1_y0 + 0.00544774*u_x0_y1*u_x2_y0 - 0.305412*u_x0_y1*v_x0_y0 + 0.00557443*u_x0_y1*v_x0_y1 + 0.0126246*u_x0_y1*v_x0_y2 - 0.00586795*u_x0_y1*v_x1_y1 + 0.02207*u_x0_y1*v_x2_y0 - 0.0270572*u_x0_y1 + 0.014894*u_x0_y2*u_x1_y0 - 0.0111483*u_x0_y2*v_x0_y0 + 0.0713959*u_x0_y2 + 0.0057282*u_x1_y0**2*v_x0_y0 + 0.0179623*u_x1_y0**2 - 0.0070172*u_x1_y0*u_x1_y1 + 0.0122718*u_x1_y0*u_x2_y0 - 0.0241339*u_x1_y0*v_x0_y0 + 0.0118068*u_x1_y0*v_x0_y1 - 0.0410802*u_x1_y0 + 0.00588209*u_x1_y1*v_x0_y0 - 0.0087171*u_x2_y0*v_x0_y0 + 0.0690541*u_x2_y0 + 0.00689714*v_x0_y0**2 - 0.0107227*v_x0_y0*v_x0_y1 - 0.0590693*v_x0_y0 + 0.0253305*v_x0_y1 - 0.0271833*v_x0_y2 + 0.00938005*v_x1_y0 + 0.00568123*v_x1_y1 - 0.0228915\n",
      "derivative of v:  -0.00697465*u_x0_y0**3 + 0.00883391*u_x0_y0**2*v_x0_y0 - 0.00629282*u_x0_y0**2*v_x0_y1 + 0.0222578*u_x0_y0**2*v_x1_y0 + 0.106423*u_x0_y0**2 - 0.00503785*u_x0_y0*u_x0_y2*v_x1_y0 - 0.0204151*u_x0_y0*u_x0_y2 - 0.0117957*u_x0_y0*u_x2_y0 + 0.00719415*u_x0_y0*v_x0_y0**2 + 0.00611347*u_x0_y0*v_x0_y0*v_x0_y1*v_x1_y0 - 0.0178939*u_x0_y0*v_x0_y0*v_x0_y1 - 0.0209863*u_x0_y0*v_x0_y0*v_x1_y0 - 0.017872*u_x0_y0*v_x0_y0 + 0.0106134*u_x0_y0*v_x0_y1**2 + 0.0150818*u_x0_y0*v_x0_y1*v_x1_y0 - 0.023007*u_x0_y0*v_x1_y0**2 - 0.227978*u_x0_y0*v_x1_y0 - 0.009781*u_x0_y0 - 0.00643527*u_x0_y1*v_x0_y0 + 0.0215257*u_x0_y1 - 0.00653159*u_x0_y2*u_x2_y0 + 0.00620484*u_x0_y2*v_x0_y0 + 0.0370954*u_x0_y2*v_x1_y0 + 0.0050493*u_x0_y2 - 0.0069525*u_x1_y0*v_x0_y0 + 0.0102627*u_x1_y0*v_x0_y1 + 0.019704*u_x1_y0 + 0.0280182*u_x2_y0*v_x1_y0 - 0.00904882*v_x0_y0**3 + 0.027099*v_x0_y0**2*v_x0_y1 + 0.122553*v_x0_y0**2 - 0.0265785*v_x0_y0*v_x0_y1**2 + 0.0112302*v_x0_y0*v_x0_y1*v_x1_y0 - 0.242195*v_x0_y0*v_x0_y1 - 0.00926858*v_x0_y0*v_x0_y2 + 0.0124194*v_x0_y0*v_x1_y0**2 - 0.00550097*v_x0_y0*v_x1_y0 - 0.0114211*v_x0_y0*v_x2_y0 - 0.0329354*v_x0_y0 + 0.0085008*v_x0_y1**3 - 0.00702215*v_x0_y1**2*v_x1_y0 + 0.0992166*v_x0_y1**2 + 0.0246721*v_x0_y1*v_x0_y2 - 0.00900403*v_x0_y1*v_x1_y0**2 - 0.00691843*v_x0_y1*v_x1_y0 + 0.0247094*v_x0_y1*v_x2_y0 - 0.015965*v_x0_y1 + 0.00508728*v_x0_y2*v_x1_y0 - 0.00551971*v_x0_y2*v_x2_y0 + 0.0721367*v_x0_y2 + 0.00760306*v_x1_y0**3 + 0.098194*v_x1_y0**2 - 0.00675569*v_x1_y0*v_x1_y1 + 0.00583211*v_x1_y0*v_x2_y0 - 0.0172569*v_x1_y0 + 0.0637368*v_x2_y0 - 0.344443\n",
      "step_num: 1 -- epoch: 101 -- lr: 0.001 -- loss: 19.174036979675293\n",
      "step_num: 1 -- epoch: 102 -- lr: 0.001 -- loss: 18.975057125091553\n",
      "step_num: 1 -- epoch: 103 -- lr: 0.001 -- loss: 18.734610557556152\n",
      "step_num: 1 -- epoch: 104 -- lr: 0.001 -- loss: 18.56258535385132\n",
      "step_num: 1 -- epoch: 105 -- lr: 0.001 -- loss: 18.365278244018555\n",
      "step_num: 1 -- epoch: 106 -- lr: 0.001 -- loss: 18.19747304916382\n",
      "step_num: 1 -- epoch: 107 -- lr: 0.001 -- loss: 18.006415367126465\n",
      "step_num: 1 -- epoch: 108 -- lr: 0.001 -- loss: 17.835813999176025\n",
      "step_num: 1 -- epoch: 109 -- lr: 0.001 -- loss: 17.692006587982178\n",
      "step_num: 1 -- epoch: 110 -- lr: 0.001 -- loss: 17.553242206573486\n",
      "step_num: 1 -- epoch: 111 -- lr: 0.001 -- loss: 17.39474105834961\n",
      "step_num: 1 -- epoch: 112 -- lr: 0.001 -- loss: 17.26192855834961\n",
      "step_num: 1 -- epoch: 113 -- lr: 0.001 -- loss: 17.133384704589844\n",
      "step_num: 1 -- epoch: 114 -- lr: 0.001 -- loss: 17.007593631744385\n",
      "step_num: 1 -- epoch: 115 -- lr: 0.001 -- loss: 16.87376832962036\n",
      "step_num: 1 -- epoch: 116 -- lr: 0.001 -- loss: 16.751718997955322\n",
      "step_num: 1 -- epoch: 117 -- lr: 0.001 -- loss: 16.634061813354492\n",
      "step_num: 1 -- epoch: 118 -- lr: 0.001 -- loss: 16.510546684265137\n",
      "step_num: 1 -- epoch: 119 -- lr: 0.001 -- loss: 16.376564502716064\n",
      "step_num: 1 -- epoch: 120 -- lr: 0.001 -- loss: 16.25337028503418\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 121 -- lr: 0.001 -- loss: 13.706443786621094\n",
      "step_num: 1 -- epoch: 122 -- lr: 0.001 -- loss: 13.56851315498352\n",
      "step_num: 1 -- epoch: 123 -- lr: 0.001 -- loss: 13.423786163330078\n",
      "step_num: 1 -- epoch: 124 -- lr: 0.001 -- loss: 13.281730651855469\n",
      "step_num: 1 -- epoch: 125 -- lr: 0.001 -- loss: 13.137969255447388\n",
      "step_num: 1 -- epoch: 126 -- lr: 0.001 -- loss: 12.999815464019775\n",
      "step_num: 1 -- epoch: 127 -- lr: 0.001 -- loss: 12.86373233795166\n",
      "step_num: 1 -- epoch: 128 -- lr: 0.001 -- loss: 12.724680185317993\n",
      "step_num: 1 -- epoch: 129 -- lr: 0.001 -- loss: 12.59507131576538\n",
      "step_num: 1 -- epoch: 130 -- lr: 0.001 -- loss: 12.457519769668579\n",
      "step_num: 1 -- epoch: 131 -- lr: 0.001 -- loss: 12.323277235031128\n",
      "step_num: 1 -- epoch: 132 -- lr: 0.001 -- loss: 12.18212604522705\n",
      "step_num: 1 -- epoch: 133 -- lr: 0.001 -- loss: 12.04548692703247\n",
      "step_num: 1 -- epoch: 134 -- lr: 0.001 -- loss: 11.903201341629028\n",
      "step_num: 1 -- epoch: 135 -- lr: 0.001 -- loss: 11.760475635528564\n",
      "step_num: 1 -- epoch: 136 -- lr: 0.001 -- loss: 11.634069681167603\n",
      "step_num: 1 -- epoch: 137 -- lr: 0.001 -- loss: 11.467008590698242\n",
      "step_num: 1 -- epoch: 138 -- lr: 0.001 -- loss: 11.31807565689087\n",
      "step_num: 1 -- epoch: 139 -- lr: 0.001 -- loss: 11.156441926956177\n",
      "step_num: 1 -- epoch: 140 -- lr: 0.001 -- loss: 11.00059723854065\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 141 -- lr: 0.001 -- loss: 11.117727041244507\n",
      "step_num: 1 -- epoch: 142 -- lr: 0.001 -- loss: 10.926922798156738\n",
      "step_num: 1 -- epoch: 143 -- lr: 0.001 -- loss: 10.70544171333313\n",
      "step_num: 1 -- epoch: 144 -- lr: 0.001 -- loss: 10.491083860397339\n",
      "step_num: 1 -- epoch: 145 -- lr: 0.001 -- loss: 10.298960447311401\n",
      "step_num: 1 -- epoch: 146 -- lr: 0.001 -- loss: 10.10356616973877\n",
      "step_num: 1 -- epoch: 147 -- lr: 0.001 -- loss: 9.922772884368896\n",
      "step_num: 1 -- epoch: 148 -- lr: 0.001 -- loss: 9.721422672271729\n",
      "step_num: 1 -- epoch: 149 -- lr: 0.001 -- loss: 9.533314228057861\n",
      "step_num: 1 -- epoch: 150 -- lr: 0.001 -- loss: 9.361279010772705\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.013894605 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -0.00935272*u_x0_y0**2*u_x1_y0 + 0.00552209*u_x0_y0**2 + 0.00903071*u_x0_y0*u_x0_y1**2 - 0.00774718*u_x0_y0*u_x0_y1*u_x1_y0*v_x0_y0 + 0.0092637*u_x0_y0*u_x0_y1*v_x0_y0 + 0.0238328*u_x0_y0*u_x0_y1 - 0.0100245*u_x0_y0*u_x1_y0**2 + 0.00727174*u_x0_y0*u_x1_y0*v_x0_y0 - 0.498791*u_x0_y0*u_x1_y0 + 0.454919*u_x0_y0*v_x0_y0 - 0.0100331*u_x0_y0*v_x0_y1 + 0.00711407*u_x0_y0*v_x0_y2 + 0.009448*u_x0_y0*v_x2_y0 - 0.0276527*u_x0_y0 - 0.0113205*u_x0_y1**2*v_x0_y0 + 0.0140827*u_x0_y1**2 + 0.2952*u_x0_y1*u_x1_y0 - 0.00948894*u_x0_y1*v_x0_y0**2 - 0.468443*u_x0_y1*v_x0_y0 + 0.00578178*u_x0_y1*v_x0_y1 + 0.0170706*u_x0_y1*v_x0_y2 - 0.00909215*u_x0_y1*v_x1_y0 + 0.0157385*u_x0_y1*v_x2_y0 - 0.0154213*u_x0_y1 + 0.0148566*u_x0_y2*u_x1_y0 + 0.0584821*u_x0_y2 + 0.00693246*u_x1_y0**2*v_x0_y0 + 0.0271292*u_x1_y0**2 + 0.0139314*u_x1_y0*u_x2_y0 + 0.00947897*u_x1_y0*v_x0_y0 - 0.033413*u_x1_y0 + 0.00505789*u_x2_y0*v_x0_y0 + 0.0560202*u_x2_y0 + 0.00645285*v_x0_y0**2 - 0.00838433*v_x0_y0*v_x1_y0 - 0.00507721*v_x0_y0*v_x1_y1 - 0.00546545*v_x0_y0*v_x2_y0 - 0.0177422*v_x0_y0 + 0.0118992*v_x0_y1 - 0.0144258*v_x1_y0 - 0.0164316*v_x2_y0\n",
      "derivative of v:  -0.00632618*u_x0_y0**3 + 0.00926231*u_x0_y0**2*v_x0_y0 - 0.00907907*u_x0_y0**2*v_x0_y1 + 0.0239536*u_x0_y0**2*v_x1_y0 + 0.173095*u_x0_y0**2 - 0.00927461*u_x0_y0*u_x0_y1 + 0.00941817*u_x0_y0*u_x0_y2 - 0.00620358*u_x0_y0*u_x1_y0 + 0.00867924*u_x0_y0*u_x1_y1 + 0.00871669*u_x0_y0*u_x2_y0 - 0.0156639*u_x0_y0*v_x0_y0*v_x0_y1 - 0.0206546*u_x0_y0*v_x0_y0*v_x1_y0 - 0.0645387*u_x0_y0*v_x0_y0 + 0.0163385*u_x0_y0*v_x0_y1**2 + 0.00877674*u_x0_y0*v_x0_y1*v_x1_y0 - 0.0229737*u_x0_y0*v_x1_y0**2 - 0.459829*u_x0_y0*v_x1_y0 + 0.0059279*u_x0_y0*v_x1_y1 - 0.0308559*u_x0_y0 - 0.0113923*u_x0_y1*v_x0_y0 + 0.00557953*u_x0_y1*v_x0_y1 + 0.00831554*u_x0_y1 + 0.027947*u_x0_y2*v_x1_y0 - 0.0141943*u_x0_y2 - 0.0054829*u_x1_y0*v_x0_y0 - 0.0205897*u_x1_y0 - 0.00931166*u_x1_y1*v_x1_y0 + 0.00526982*u_x2_y0*v_x0_y1 + 0.0215777*u_x2_y0*v_x1_y0 - 0.00725397*v_x0_y0**3 + 0.0254091*v_x0_y0**2*v_x0_y1 + 0.176402*v_x0_y0**2 - 0.0255872*v_x0_y0*v_x0_y1**2 + 0.00514459*v_x0_y0*v_x0_y1*v_x1_y0 - 0.476602*v_x0_y0*v_x0_y1 + 0.010717*v_x0_y0*v_x0_y2 + 0.0176409*v_x0_y0*v_x1_y0**2 + 0.00841043*v_x0_y0*v_x2_y0 - 0.0118138*v_x0_y0 + 0.005834*v_x0_y1**3 + 0.0835243*v_x0_y1**2 + 0.020654*v_x0_y1*v_x0_y2 - 0.00584664*v_x0_y1*v_x1_y0**2 - 0.0563145*v_x0_y1*v_x1_y0 + 0.0257211*v_x0_y1*v_x2_y0 - 0.0401304*v_x0_y1 + 0.0594673*v_x0_y2 + 0.0744441*v_x1_y0**2 - 0.0432298*v_x1_y0 + 0.0578254*v_x2_y0 - 0.555318\n",
      "step_num: 1 -- epoch: 151 -- lr: 0.001 -- loss: 9.164344549179077\n",
      "step_num: 1 -- epoch: 152 -- lr: 0.001 -- loss: 8.974786043167114\n",
      "step_num: 1 -- epoch: 153 -- lr: 0.001 -- loss: 8.800065279006958\n",
      "step_num: 1 -- epoch: 154 -- lr: 0.001 -- loss: 8.60963487625122\n",
      "step_num: 1 -- epoch: 155 -- lr: 0.001 -- loss: 8.434817790985107\n",
      "step_num: 1 -- epoch: 156 -- lr: 0.001 -- loss: 8.24316692352295\n",
      "step_num: 1 -- epoch: 157 -- lr: 0.001 -- loss: 8.059978008270264\n",
      "step_num: 1 -- epoch: 158 -- lr: 0.001 -- loss: 7.873504400253296\n",
      "step_num: 1 -- epoch: 159 -- lr: 0.001 -- loss: 7.688328504562378\n",
      "step_num: 1 -- epoch: 160 -- lr: 0.001 -- loss: 7.500185966491699\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 161 -- lr: 0.001 -- loss: 7.589342951774597\n",
      "step_num: 1 -- epoch: 162 -- lr: 0.001 -- loss: 7.392964601516724\n",
      "step_num: 1 -- epoch: 163 -- lr: 0.001 -- loss: 7.166440963745117\n",
      "step_num: 1 -- epoch: 164 -- lr: 0.001 -- loss: 6.933298110961914\n",
      "step_num: 1 -- epoch: 165 -- lr: 0.001 -- loss: 6.717525243759155\n",
      "step_num: 1 -- epoch: 166 -- lr: 0.001 -- loss: 6.502709984779358\n",
      "step_num: 1 -- epoch: 167 -- lr: 0.001 -- loss: 6.297895550727844\n",
      "step_num: 1 -- epoch: 168 -- lr: 0.001 -- loss: 6.1052833795547485\n",
      "step_num: 1 -- epoch: 169 -- lr: 0.001 -- loss: 5.907947301864624\n",
      "step_num: 1 -- epoch: 170 -- lr: 0.001 -- loss: 5.710446000099182\n",
      "step_num: 1 -- epoch: 171 -- lr: 0.001 -- loss: 5.526608228683472\n",
      "step_num: 1 -- epoch: 172 -- lr: 0.001 -- loss: 5.331255316734314\n",
      "step_num: 1 -- epoch: 173 -- lr: 0.001 -- loss: 5.156921982765198\n",
      "step_num: 1 -- epoch: 174 -- lr: 0.001 -- loss: 4.981463313102722\n",
      "step_num: 1 -- epoch: 175 -- lr: 0.001 -- loss: 4.798385262489319\n",
      "step_num: 1 -- epoch: 176 -- lr: 0.001 -- loss: 4.630389451980591\n",
      "step_num: 1 -- epoch: 177 -- lr: 0.001 -- loss: 4.463711380958557\n",
      "step_num: 1 -- epoch: 178 -- lr: 0.001 -- loss: 4.302345871925354\n",
      "step_num: 1 -- epoch: 179 -- lr: 0.001 -- loss: 4.138827681541443\n",
      "step_num: 1 -- epoch: 180 -- lr: 0.001 -- loss: 3.9777495861053467\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 181 -- lr: 0.001 -- loss: 4.182274699211121\n",
      "step_num: 1 -- epoch: 182 -- lr: 0.001 -- loss: 4.000288367271423\n",
      "step_num: 1 -- epoch: 183 -- lr: 0.001 -- loss: 3.8161280155181885\n",
      "step_num: 1 -- epoch: 184 -- lr: 0.001 -- loss: 3.6277530789375305\n",
      "step_num: 1 -- epoch: 185 -- lr: 0.001 -- loss: 3.455286145210266\n",
      "step_num: 1 -- epoch: 186 -- lr: 0.001 -- loss: 3.276962399482727\n",
      "step_num: 1 -- epoch: 187 -- lr: 0.001 -- loss: 3.118022918701172\n",
      "step_num: 1 -- epoch: 188 -- lr: 0.001 -- loss: 2.9554760456085205\n",
      "step_num: 1 -- epoch: 189 -- lr: 0.001 -- loss: 2.8118638396263123\n",
      "step_num: 1 -- epoch: 190 -- lr: 0.001 -- loss: 2.667802333831787\n",
      "step_num: 1 -- epoch: 191 -- lr: 0.001 -- loss: 2.532052159309387\n",
      "step_num: 1 -- epoch: 192 -- lr: 0.001 -- loss: 2.401999771595001\n",
      "step_num: 1 -- epoch: 193 -- lr: 0.001 -- loss: 2.2792147994041443\n",
      "step_num: 1 -- epoch: 194 -- lr: 0.001 -- loss: 2.1632575392723083\n",
      "step_num: 1 -- epoch: 195 -- lr: 0.001 -- loss: 2.046242415904999\n",
      "step_num: 1 -- epoch: 196 -- lr: 0.001 -- loss: 1.9384470582008362\n",
      "step_num: 1 -- epoch: 197 -- lr: 0.001 -- loss: 1.8368202447891235\n",
      "step_num: 1 -- epoch: 198 -- lr: 0.001 -- loss: 1.7356651723384857\n",
      "step_num: 1 -- epoch: 199 -- lr: 0.001 -- loss: 1.653530329465866\n",
      "step_num: 1 -- epoch: 200 -- lr: 0.001 -- loss: 1.5596464574337006\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0052136863 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.00609661*u_x0_y0**2*u_x0_y1 - 0.00554722*u_x0_y0**2*u_x1_y0 + 0.00983752*u_x0_y0**2 + 0.0539027*u_x0_y0*u_x0_y1 - 0.827425*u_x0_y0*u_x1_y0 + 0.316816*u_x0_y0*v_x0_y0 + 0.00633818*u_x0_y0*v_x0_y1 + 0.013695*u_x0_y0*v_x0_y2 + 0.0161943*u_x0_y0*v_x2_y0 + 0.0312576*u_x0_y0 + 0.00687827*u_x0_y1**2 + 0.0994001*u_x0_y1*u_x1_y0 - 0.00551893*u_x0_y1*v_x0_y0**2 - 0.794275*u_x0_y1*v_x0_y0 + 0.0083653*u_x0_y1*v_x0_y1 + 0.0132062*u_x0_y1*v_x0_y2 - 0.00658746*u_x0_y1*v_x1_y0 + 0.0104868*u_x0_y1*v_x2_y0 + 0.00588606*u_x0_y1 + 0.0109605*u_x0_y2*u_x1_y0 + 0.00935014*u_x0_y2*v_x0_y0 + 0.0576813*u_x0_y2 + 0.0165205*u_x1_y0**2 + 0.00687409*u_x1_y0*u_x2_y0 + 0.0056648*u_x1_y0*v_x0_y0**2 + 0.0422665*u_x1_y0*v_x0_y0 - 0.0160069*u_x1_y0*v_x1_y0 - 0.0105475*u_x1_y0 + 0.014165*u_x2_y0*v_x0_y0 + 0.0594677*u_x2_y0 + 0.0217264*v_x0_y0**2 + 0.00967592*v_x0_y0*v_x0_y1 - 0.00833185*v_x0_y0*v_x1_y0 + 0.00564087*v_x0_y0*v_x1_y1 + 0.00841362*v_x1_y0 + 0.00741393*v_x2_y0 - 0.057716\n",
      "derivative of v:  0.124504*u_x0_y0**2 + 0.00645663*u_x0_y0*u_x0_y2 + 0.0118505*u_x0_y0*u_x2_y0 - 0.0662418*u_x0_y0*v_x0_y0 - 0.0281236*u_x0_y0*v_x0_y1 - 0.881002*u_x0_y0*v_x1_y0 - 0.0498293*u_x0_y0 - 0.00693486*u_x0_y1*v_x1_y0 + 0.00662907*u_x0_y2*v_x1_y0 - 0.00823305*u_x1_y0*v_x0_y0 - 0.00880844*u_x2_y0*v_x0_y0 + 0.00639242*u_x2_y0*v_x1_y0 - 0.013127*u_x2_y0 + 0.115067*v_x0_y0**2 - 0.892657*v_x0_y0*v_x0_y1 + 0.00605644*v_x0_y0*v_x0_y2 - 0.0397888*v_x0_y0*v_x1_y0 + 0.0064721*v_x0_y0*v_x2_y0 - 0.0125097*v_x0_y0 + 0.0244361*v_x0_y1**2 - 0.0205349*v_x0_y1*v_x1_y0 + 0.00539372*v_x0_y1*v_x2_y0 + 0.00640278*v_x0_y1 + 0.0568932*v_x0_y2 + 0.0302296*v_x1_y0**2 - 0.0166273*v_x1_y0 + 0.0597187*v_x2_y0 - 0.553702\n",
      "step_num: 1 -- epoch: 201 -- lr: 0.001 -- loss: 1.303518921136856\n",
      "step_num: 1 -- epoch: 202 -- lr: 0.001 -- loss: 1.2284323871135712\n",
      "step_num: 1 -- epoch: 203 -- lr: 0.001 -- loss: 1.1652861535549164\n",
      "step_num: 1 -- epoch: 204 -- lr: 0.001 -- loss: 1.1025612652301788\n",
      "step_num: 1 -- epoch: 205 -- lr: 0.001 -- loss: 1.04948291182518\n",
      "step_num: 1 -- epoch: 206 -- lr: 0.001 -- loss: 1.0015279352664948\n",
      "step_num: 1 -- epoch: 207 -- lr: 0.001 -- loss: 0.9515512585639954\n",
      "step_num: 1 -- epoch: 208 -- lr: 0.001 -- loss: 0.9130323380231857\n",
      "step_num: 1 -- epoch: 209 -- lr: 0.001 -- loss: 0.8774917721748352\n",
      "step_num: 1 -- epoch: 210 -- lr: 0.001 -- loss: 0.8349282741546631\n",
      "step_num: 1 -- epoch: 211 -- lr: 0.001 -- loss: 0.8033339828252792\n",
      "step_num: 1 -- epoch: 212 -- lr: 0.001 -- loss: 0.770895853638649\n",
      "step_num: 1 -- epoch: 213 -- lr: 0.001 -- loss: 0.7452171444892883\n",
      "step_num: 1 -- epoch: 214 -- lr: 0.001 -- loss: 0.7167002856731415\n",
      "step_num: 1 -- epoch: 215 -- lr: 0.001 -- loss: 0.6944998353719711\n",
      "step_num: 1 -- epoch: 216 -- lr: 0.001 -- loss: 0.674270510673523\n",
      "step_num: 1 -- epoch: 217 -- lr: 0.001 -- loss: 0.6494812667369843\n",
      "step_num: 1 -- epoch: 218 -- lr: 0.001 -- loss: 0.6328514069318771\n",
      "step_num: 1 -- epoch: 219 -- lr: 0.001 -- loss: 0.6138126254081726\n",
      "step_num: 1 -- epoch: 220 -- lr: 0.001 -- loss: 0.5978085398674011\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 221 -- lr: 0.001 -- loss: 0.7076277434825897\n",
      "step_num: 1 -- epoch: 222 -- lr: 0.001 -- loss: 0.6786886751651764\n",
      "step_num: 1 -- epoch: 223 -- lr: 0.001 -- loss: 0.6438378989696503\n",
      "step_num: 1 -- epoch: 224 -- lr: 0.001 -- loss: 0.6171227395534515\n",
      "step_num: 1 -- epoch: 225 -- lr: 0.001 -- loss: 0.5954555422067642\n",
      "step_num: 1 -- epoch: 226 -- lr: 0.001 -- loss: 0.5810515880584717\n",
      "step_num: 1 -- epoch: 227 -- lr: 0.001 -- loss: 0.5603746771812439\n",
      "step_num: 1 -- epoch: 228 -- lr: 0.001 -- loss: 0.5433521121740341\n",
      "step_num: 1 -- epoch: 229 -- lr: 0.001 -- loss: 0.5296176075935364\n",
      "step_num: 1 -- epoch: 230 -- lr: 0.001 -- loss: 0.5166589319705963\n",
      "step_num: 1 -- epoch: 231 -- lr: 0.001 -- loss: 0.5043806433677673\n",
      "step_num: 1 -- epoch: 232 -- lr: 0.001 -- loss: 0.49393050372600555\n",
      "step_num: 1 -- epoch: 233 -- lr: 0.001 -- loss: 0.4852195382118225\n",
      "step_num: 1 -- epoch: 234 -- lr: 0.001 -- loss: 0.4773678481578827\n",
      "step_num: 1 -- epoch: 235 -- lr: 0.001 -- loss: 0.46851131319999695\n",
      "step_num: 1 -- epoch: 236 -- lr: 0.001 -- loss: 0.4613824933767319\n",
      "step_num: 1 -- epoch: 237 -- lr: 0.001 -- loss: 0.45518194139003754\n",
      "step_num: 1 -- epoch: 238 -- lr: 0.001 -- loss: 0.4494076818227768\n",
      "step_num: 1 -- epoch: 239 -- lr: 0.001 -- loss: 0.44377681612968445\n",
      "step_num: 1 -- epoch: 240 -- lr: 0.001 -- loss: 0.4387725442647934\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 241 -- lr: 0.001 -- loss: 0.4862947314977646\n",
      "step_num: 1 -- epoch: 242 -- lr: 0.001 -- loss: 0.47653821110725403\n",
      "step_num: 1 -- epoch: 243 -- lr: 0.001 -- loss: 0.4625407010316849\n",
      "step_num: 1 -- epoch: 244 -- lr: 0.001 -- loss: 0.45135557651519775\n",
      "step_num: 1 -- epoch: 245 -- lr: 0.001 -- loss: 0.4414479434490204\n",
      "step_num: 1 -- epoch: 246 -- lr: 0.001 -- loss: 0.4348890334367752\n",
      "step_num: 1 -- epoch: 247 -- lr: 0.001 -- loss: 0.4289550334215164\n",
      "step_num: 1 -- epoch: 248 -- lr: 0.001 -- loss: 0.42128250002861023\n",
      "step_num: 1 -- epoch: 249 -- lr: 0.001 -- loss: 0.41521403193473816\n",
      "step_num: 1 -- epoch: 250 -- lr: 0.001 -- loss: 0.41019704937934875\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0024242455 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.043463*u_x0_y0**2 + 0.0199006*u_x0_y0*u_x0_y1 - 0.99017*u_x0_y0*u_x1_y0 + 0.00793163*u_x0_y0*u_x1_y1 + 0.00634731*u_x0_y0*u_x2_y0 + 0.101257*u_x0_y0*v_x0_y0 + 0.00561256*u_x0_y0*v_x0_y2 - 0.0397472*u_x0_y0 + 0.00628113*u_x0_y1*u_x1_y0 - 0.98771*u_x0_y1*v_x0_y0 - 0.00818329*u_x0_y1 + 0.00681406*u_x0_y2*v_x0_y0 + 0.0585746*u_x0_y2 + 0.0127194*u_x1_y0*v_x0_y0 - 0.0117191*u_x1_y0 + 0.00542261*u_x2_y0*v_x0_y0 + 0.0576058*u_x2_y0 + 0.0279161*v_x0_y0**2 - 0.0411822*v_x0_y0 - 0.0414408\n",
      "derivative of v:  0.0839834*u_x0_y0**2 + 0.00940011*u_x0_y0*v_x0_y0 - 0.999388*u_x0_y0*v_x1_y0 + 0.00943163*u_x0_y0*v_x1_y1 - 0.0123088*u_x0_y0 + 0.0703996*v_x0_y0**2 - 1.00309*v_x0_y0*v_x0_y1 + 0.00572745*v_x0_y0*v_x2_y0 - 0.0139262*v_x0_y0 + 0.0250037*v_x0_y1**2 + 0.00656015*v_x0_y1 + 0.0611139*v_x0_y2 + 0.0248015*v_x1_y0**2 - 0.00634901*v_x1_y1 + 0.0598197*v_x2_y0 - 0.452553\n",
      "step_num: 1 -- epoch: 251 -- lr: 0.001 -- loss: 0.40530456602573395\n",
      "step_num: 1 -- epoch: 252 -- lr: 0.001 -- loss: 0.4013642743229866\n",
      "step_num: 1 -- epoch: 253 -- lr: 0.001 -- loss: 0.39665476232767105\n",
      "step_num: 1 -- epoch: 254 -- lr: 0.001 -- loss: 0.3934643939137459\n",
      "step_num: 1 -- epoch: 255 -- lr: 0.001 -- loss: 0.3899950310587883\n",
      "step_num: 1 -- epoch: 256 -- lr: 0.001 -- loss: 0.38740110397338867\n",
      "step_num: 1 -- epoch: 257 -- lr: 0.001 -- loss: 0.3847373425960541\n",
      "step_num: 1 -- epoch: 258 -- lr: 0.001 -- loss: 0.38176780939102173\n",
      "step_num: 1 -- epoch: 259 -- lr: 0.001 -- loss: 0.379487082362175\n",
      "step_num: 1 -- epoch: 260 -- lr: 0.001 -- loss: 0.37757670134305954\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 261 -- lr: 0.001 -- loss: 0.3861020654439926\n",
      "step_num: 1 -- epoch: 262 -- lr: 0.001 -- loss: 0.3818742409348488\n",
      "step_num: 1 -- epoch: 263 -- lr: 0.001 -- loss: 0.3766387701034546\n",
      "step_num: 1 -- epoch: 264 -- lr: 0.001 -- loss: 0.3718911409378052\n",
      "step_num: 1 -- epoch: 265 -- lr: 0.001 -- loss: 0.36870385706424713\n",
      "step_num: 1 -- epoch: 266 -- lr: 0.001 -- loss: 0.36596400290727615\n",
      "step_num: 1 -- epoch: 267 -- lr: 0.001 -- loss: 0.36361342668533325\n",
      "step_num: 1 -- epoch: 268 -- lr: 0.001 -- loss: 0.3612620234489441\n",
      "step_num: 1 -- epoch: 269 -- lr: 0.001 -- loss: 0.35954371839761734\n",
      "step_num: 1 -- epoch: 270 -- lr: 0.001 -- loss: 0.35777992010116577\n",
      "step_num: 1 -- epoch: 271 -- lr: 0.001 -- loss: 0.35603688657283783\n",
      "step_num: 1 -- epoch: 272 -- lr: 0.001 -- loss: 0.3546363338828087\n",
      "step_num: 1 -- epoch: 273 -- lr: 0.001 -- loss: 0.35294973850250244\n",
      "step_num: 1 -- epoch: 274 -- lr: 0.001 -- loss: 0.3516533821821213\n",
      "step_num: 1 -- epoch: 275 -- lr: 0.001 -- loss: 0.35024117678403854\n",
      "step_num: 1 -- epoch: 276 -- lr: 0.001 -- loss: 0.3488483726978302\n",
      "step_num: 1 -- epoch: 277 -- lr: 0.001 -- loss: 0.3475118577480316\n",
      "step_num: 1 -- epoch: 278 -- lr: 0.001 -- loss: 0.34631314128637314\n",
      "step_num: 1 -- epoch: 279 -- lr: 0.001 -- loss: 0.3453698009252548\n",
      "step_num: 1 -- epoch: 280 -- lr: 0.001 -- loss: 0.3439335227012634\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 281 -- lr: 0.001 -- loss: 0.3784402757883072\n",
      "step_num: 1 -- epoch: 282 -- lr: 0.001 -- loss: 0.3684951364994049\n",
      "step_num: 1 -- epoch: 283 -- lr: 0.001 -- loss: 0.36384767293930054\n",
      "step_num: 1 -- epoch: 284 -- lr: 0.001 -- loss: 0.35993995517492294\n",
      "step_num: 1 -- epoch: 285 -- lr: 0.001 -- loss: 0.35736436396837234\n",
      "step_num: 1 -- epoch: 286 -- lr: 0.001 -- loss: 0.35465695708990097\n",
      "step_num: 1 -- epoch: 287 -- lr: 0.001 -- loss: 0.35125213116407394\n",
      "step_num: 1 -- epoch: 288 -- lr: 0.001 -- loss: 0.34893955290317535\n",
      "step_num: 1 -- epoch: 289 -- lr: 0.001 -- loss: 0.347339928150177\n",
      "step_num: 1 -- epoch: 290 -- lr: 0.001 -- loss: 0.345678448677063\n",
      "step_num: 1 -- epoch: 291 -- lr: 0.001 -- loss: 0.34395697712898254\n",
      "step_num: 1 -- epoch: 292 -- lr: 0.001 -- loss: 0.3426862210035324\n",
      "step_num: 1 -- epoch: 293 -- lr: 0.001 -- loss: 0.3412494584918022\n",
      "step_num: 1 -- epoch: 294 -- lr: 0.001 -- loss: 0.3409138023853302\n",
      "step_num: 1 -- epoch: 295 -- lr: 0.001 -- loss: 0.33927489817142487\n",
      "step_num: 1 -- epoch: 296 -- lr: 0.001 -- loss: 0.3384052962064743\n",
      "step_num: 1 -- epoch: 297 -- lr: 0.001 -- loss: 0.33712248504161835\n",
      "step_num: 1 -- epoch: 298 -- lr: 0.001 -- loss: 0.3364482894539833\n",
      "step_num: 1 -- epoch: 299 -- lr: 0.001 -- loss: 0.33591239899396896\n",
      "step_num: 1 -- epoch: 300 -- lr: 0.001 -- loss: 0.3348194509744644\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0018005684 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.015812*u_x0_y0**2 - 1.00387*u_x0_y0*u_x1_y0 + 0.0113665*u_x0_y0*v_x0_y0 - 0.0126603*u_x0_y0 - 1.00455*u_x0_y1*v_x0_y0 + 0.0079154*u_x0_y1*v_x0_y1 + 0.00534164*u_x0_y1*v_x1_y0 + 0.0616804*u_x0_y2 + 0.0596702*u_x2_y0 + 0.0122317*v_x0_y0**2 - 0.0111966*v_x0_y0 - 0.0440536\n",
      "derivative of v:  0.0547309*u_x0_y0**2 - 1.00785*u_x0_y0*v_x1_y0 + 0.0564082*v_x0_y0**2 - 1.00643*v_x0_y0*v_x0_y1 + 0.00653165*v_x0_y0*v_x0_y2 + 0.00566516*v_x0_y0*v_x1_y1 + 0.011604*v_x0_y0 + 0.0199098*v_x0_y1**2 + 0.00525495*v_x0_y1 + 0.0636421*v_x0_y2 + 0.0142806*v_x1_y0**2 + 0.0622312*v_x2_y0 - 0.362413\n",
      "step_num: 1 -- epoch: 301 -- lr: 0.001 -- loss: 0.3392397239804268\n",
      "step_num: 1 -- epoch: 302 -- lr: 0.001 -- loss: 0.3333723545074463\n",
      "step_num: 1 -- epoch: 303 -- lr: 0.001 -- loss: 0.32728272676467896\n",
      "step_num: 1 -- epoch: 304 -- lr: 0.001 -- loss: 0.3237496465444565\n",
      "step_num: 1 -- epoch: 305 -- lr: 0.001 -- loss: 0.32110925763845444\n",
      "step_num: 1 -- epoch: 306 -- lr: 0.001 -- loss: 0.31988685578107834\n",
      "step_num: 1 -- epoch: 307 -- lr: 0.001 -- loss: 0.3186621889472008\n",
      "step_num: 1 -- epoch: 308 -- lr: 0.001 -- loss: 0.3171784058213234\n",
      "step_num: 1 -- epoch: 309 -- lr: 0.001 -- loss: 0.3161308988928795\n",
      "step_num: 1 -- epoch: 310 -- lr: 0.001 -- loss: 0.31526102125644684\n",
      "step_num: 1 -- epoch: 311 -- lr: 0.001 -- loss: 0.31445059925317764\n",
      "step_num: 1 -- epoch: 312 -- lr: 0.001 -- loss: 0.31372636556625366\n",
      "step_num: 1 -- epoch: 313 -- lr: 0.001 -- loss: 0.31310585886240005\n",
      "step_num: 1 -- epoch: 314 -- lr: 0.001 -- loss: 0.31239182502031326\n",
      "step_num: 1 -- epoch: 315 -- lr: 0.001 -- loss: 0.31170473992824554\n",
      "step_num: 1 -- epoch: 316 -- lr: 0.001 -- loss: 0.31124668568372726\n",
      "step_num: 1 -- epoch: 317 -- lr: 0.001 -- loss: 0.3106614500284195\n",
      "step_num: 1 -- epoch: 318 -- lr: 0.001 -- loss: 0.3101283758878708\n",
      "step_num: 1 -- epoch: 319 -- lr: 0.001 -- loss: 0.3096923232078552\n",
      "step_num: 1 -- epoch: 320 -- lr: 0.001 -- loss: 0.3091564327478409\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 321 -- lr: 0.001 -- loss: 0.33198652416467667\n",
      "step_num: 1 -- epoch: 322 -- lr: 0.001 -- loss: 0.3267534375190735\n",
      "step_num: 1 -- epoch: 323 -- lr: 0.001 -- loss: 0.3235301747918129\n",
      "step_num: 1 -- epoch: 324 -- lr: 0.001 -- loss: 0.3201870694756508\n",
      "step_num: 1 -- epoch: 325 -- lr: 0.001 -- loss: 0.3189568519592285\n",
      "step_num: 1 -- epoch: 326 -- lr: 0.001 -- loss: 0.317792072892189\n",
      "step_num: 1 -- epoch: 327 -- lr: 0.001 -- loss: 0.3166992962360382\n",
      "step_num: 1 -- epoch: 328 -- lr: 0.001 -- loss: 0.31591127067804337\n",
      "step_num: 1 -- epoch: 329 -- lr: 0.001 -- loss: 0.3150084838271141\n",
      "step_num: 1 -- epoch: 330 -- lr: 0.001 -- loss: 0.3141796365380287\n",
      "step_num: 1 -- epoch: 331 -- lr: 0.001 -- loss: 0.31392446905374527\n",
      "step_num: 1 -- epoch: 332 -- lr: 0.001 -- loss: 0.3132074698805809\n",
      "step_num: 1 -- epoch: 333 -- lr: 0.001 -- loss: 0.31296755373477936\n",
      "step_num: 1 -- epoch: 334 -- lr: 0.001 -- loss: 0.31239084154367447\n",
      "step_num: 1 -- epoch: 335 -- lr: 0.001 -- loss: 0.3119796887040138\n",
      "step_num: 1 -- epoch: 336 -- lr: 0.001 -- loss: 0.3117622211575508\n",
      "step_num: 1 -- epoch: 337 -- lr: 0.001 -- loss: 0.31129544973373413\n",
      "step_num: 1 -- epoch: 338 -- lr: 0.001 -- loss: 0.3109738826751709\n",
      "step_num: 1 -- epoch: 339 -- lr: 0.001 -- loss: 0.31053436547517776\n",
      "step_num: 1 -- epoch: 340 -- lr: 0.001 -- loss: 0.3102543205022812\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 341 -- lr: 0.001 -- loss: 0.3101200684905052\n",
      "step_num: 1 -- epoch: 342 -- lr: 0.001 -- loss: 0.3083173781633377\n",
      "step_num: 1 -- epoch: 343 -- lr: 0.001 -- loss: 0.30645182728767395\n",
      "step_num: 1 -- epoch: 344 -- lr: 0.001 -- loss: 0.30500175058841705\n",
      "step_num: 1 -- epoch: 345 -- lr: 0.001 -- loss: 0.30340394377708435\n",
      "step_num: 1 -- epoch: 346 -- lr: 0.001 -- loss: 0.3025079220533371\n",
      "step_num: 1 -- epoch: 347 -- lr: 0.001 -- loss: 0.3017127588391304\n",
      "step_num: 1 -- epoch: 348 -- lr: 0.001 -- loss: 0.3012045696377754\n",
      "step_num: 1 -- epoch: 349 -- lr: 0.001 -- loss: 0.3005559742450714\n",
      "step_num: 1 -- epoch: 350 -- lr: 0.001 -- loss: 0.29986049234867096\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.001564082 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.00962777*u_x0_y0**2 - 1.00466*u_x0_y0*u_x1_y0 - 1.00569*u_x0_y1*v_x0_y0 + 0.0601795*u_x0_y2 + 0.0581797*u_x2_y0 + 0.00723431*v_x0_y0**2 - 0.035283\n",
      "derivative of v:  0.0493448*u_x0_y0**2 + 0.0110044*u_x0_y0*v_x0_y0 - 1.00796*u_x0_y0*v_x1_y0 + 0.00583303*u_x0_y0 + 0.0553536*v_x0_y0**2 - 1.00664*v_x0_y0*v_x0_y1 + 0.00595602*v_x0_y0*v_x0_y2 + 0.0149859*v_x0_y1**2 + 0.0603571*v_x0_y2 + 0.0147301*v_x1_y0**2 + 0.00507476*v_x1_y0 - 0.00566108*v_x1_y1 + 0.0597821*v_x2_y0 - 0.282382\n",
      "step_num: 1 -- epoch: 351 -- lr: 0.001 -- loss: 0.29940786957740784\n",
      "step_num: 1 -- epoch: 352 -- lr: 0.001 -- loss: 0.2989840656518936\n",
      "step_num: 1 -- epoch: 353 -- lr: 0.001 -- loss: 0.29862239211797714\n",
      "step_num: 1 -- epoch: 354 -- lr: 0.001 -- loss: 0.29817697405815125\n",
      "step_num: 1 -- epoch: 355 -- lr: 0.001 -- loss: 0.29776153713464737\n",
      "step_num: 1 -- epoch: 356 -- lr: 0.001 -- loss: 0.2974464073777199\n",
      "step_num: 1 -- epoch: 357 -- lr: 0.001 -- loss: 0.2972249388694763\n",
      "step_num: 1 -- epoch: 358 -- lr: 0.001 -- loss: 0.29685384035110474\n",
      "step_num: 1 -- epoch: 359 -- lr: 0.001 -- loss: 0.2966604009270668\n",
      "step_num: 1 -- epoch: 360 -- lr: 0.001 -- loss: 0.2963969334959984\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 361 -- lr: 0.001 -- loss: 0.31111064553260803\n",
      "step_num: 1 -- epoch: 362 -- lr: 0.001 -- loss: 0.30961403250694275\n",
      "step_num: 1 -- epoch: 363 -- lr: 0.001 -- loss: 0.3071932941675186\n",
      "step_num: 1 -- epoch: 364 -- lr: 0.001 -- loss: 0.30587004125118256\n",
      "step_num: 1 -- epoch: 365 -- lr: 0.001 -- loss: 0.305073507130146\n",
      "step_num: 1 -- epoch: 366 -- lr: 0.001 -- loss: 0.3036935031414032\n",
      "step_num: 1 -- epoch: 367 -- lr: 0.001 -- loss: 0.30337896198034286\n",
      "step_num: 1 -- epoch: 368 -- lr: 0.001 -- loss: 0.30249446630477905\n",
      "step_num: 1 -- epoch: 369 -- lr: 0.001 -- loss: 0.30228178948163986\n",
      "step_num: 1 -- epoch: 370 -- lr: 0.001 -- loss: 0.3015506863594055\n",
      "step_num: 1 -- epoch: 371 -- lr: 0.001 -- loss: 0.30106402188539505\n",
      "step_num: 1 -- epoch: 372 -- lr: 0.001 -- loss: 0.3007718101143837\n",
      "step_num: 1 -- epoch: 373 -- lr: 0.001 -- loss: 0.3003443479537964\n",
      "step_num: 1 -- epoch: 374 -- lr: 0.001 -- loss: 0.299862839281559\n",
      "step_num: 1 -- epoch: 375 -- lr: 0.001 -- loss: 0.2996255159378052\n",
      "step_num: 1 -- epoch: 376 -- lr: 0.001 -- loss: 0.2995132729411125\n",
      "step_num: 1 -- epoch: 377 -- lr: 0.001 -- loss: 0.299057275056839\n",
      "step_num: 1 -- epoch: 378 -- lr: 0.001 -- loss: 0.2990424782037735\n",
      "step_num: 1 -- epoch: 379 -- lr: 0.001 -- loss: 0.2985175848007202\n",
      "step_num: 1 -- epoch: 380 -- lr: 0.001 -- loss: 0.29831770062446594\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 381 -- lr: 0.001 -- loss: 0.3126971572637558\n",
      "step_num: 1 -- epoch: 382 -- lr: 0.001 -- loss: 0.3111328110098839\n",
      "step_num: 1 -- epoch: 383 -- lr: 0.001 -- loss: 0.3097754567861557\n",
      "step_num: 1 -- epoch: 384 -- lr: 0.001 -- loss: 0.3085548207163811\n",
      "step_num: 1 -- epoch: 385 -- lr: 0.001 -- loss: 0.30767054110765457\n",
      "step_num: 1 -- epoch: 386 -- lr: 0.001 -- loss: 0.30679916590452194\n",
      "step_num: 1 -- epoch: 387 -- lr: 0.001 -- loss: 0.3061610832810402\n",
      "step_num: 1 -- epoch: 388 -- lr: 0.001 -- loss: 0.30549153685569763\n",
      "step_num: 1 -- epoch: 389 -- lr: 0.001 -- loss: 0.3050745651125908\n",
      "step_num: 1 -- epoch: 390 -- lr: 0.001 -- loss: 0.3046570047736168\n",
      "step_num: 1 -- epoch: 391 -- lr: 0.001 -- loss: 0.3041745647788048\n",
      "step_num: 1 -- epoch: 392 -- lr: 0.001 -- loss: 0.30398692190647125\n",
      "step_num: 1 -- epoch: 393 -- lr: 0.001 -- loss: 0.30362483859062195\n",
      "step_num: 1 -- epoch: 394 -- lr: 0.001 -- loss: 0.30334968119859695\n",
      "step_num: 1 -- epoch: 395 -- lr: 0.001 -- loss: 0.3030492514371872\n",
      "step_num: 1 -- epoch: 396 -- lr: 0.001 -- loss: 0.3028741180896759\n",
      "step_num: 1 -- epoch: 397 -- lr: 0.001 -- loss: 0.3026508018374443\n",
      "step_num: 1 -- epoch: 398 -- lr: 0.001 -- loss: 0.3026917949318886\n",
      "step_num: 1 -- epoch: 399 -- lr: 0.001 -- loss: 0.3022889643907547\n",
      "step_num: 1 -- epoch: 400 -- lr: 0.001 -- loss: 0.30186739563941956\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0015324502 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  0.00609373*u_x0_y0**2 - 1.006*u_x0_y0*u_x1_y0 - 1.00525*u_x0_y1*v_x0_y0 + 0.0590658*u_x0_y2 + 0.0607493*u_x2_y0 - 0.00595925*v_x1_y0 - 0.0292632\n",
      "derivative of v:  0.034652*u_x0_y0**2 - 0.00764475*u_x0_y0*v_x0_y0 - 1.00686*u_x0_y0*v_x1_y0 + 0.0365274*v_x0_y0**2 - 1.00592*v_x0_y0*v_x0_y1 + 0.0124758*v_x0_y1**2 + 0.0585823*v_x0_y2 + 0.0122084*v_x1_y0**2 + 0.0616211*v_x2_y0 - 0.218065\n",
      "step_num: 1 -- epoch: 401 -- lr: 0.001 -- loss: 0.30096790939569473\n",
      "step_num: 1 -- epoch: 402 -- lr: 0.001 -- loss: 0.29982544481754303\n",
      "step_num: 1 -- epoch: 403 -- lr: 0.001 -- loss: 0.297881118953228\n",
      "step_num: 1 -- epoch: 404 -- lr: 0.001 -- loss: 0.2970280572772026\n",
      "step_num: 1 -- epoch: 405 -- lr: 0.001 -- loss: 0.29658788442611694\n",
      "step_num: 1 -- epoch: 406 -- lr: 0.001 -- loss: 0.29612498730421066\n",
      "step_num: 1 -- epoch: 407 -- lr: 0.001 -- loss: 0.29580581188201904\n",
      "step_num: 1 -- epoch: 408 -- lr: 0.001 -- loss: 0.29530659317970276\n",
      "step_num: 1 -- epoch: 409 -- lr: 0.001 -- loss: 0.2950107231736183\n",
      "step_num: 1 -- epoch: 410 -- lr: 0.001 -- loss: 0.2946285307407379\n",
      "step_num: 1 -- epoch: 411 -- lr: 0.001 -- loss: 0.29438626766204834\n",
      "step_num: 1 -- epoch: 412 -- lr: 0.001 -- loss: 0.2941072806715965\n",
      "step_num: 1 -- epoch: 413 -- lr: 0.001 -- loss: 0.2937973812222481\n",
      "step_num: 1 -- epoch: 414 -- lr: 0.001 -- loss: 0.29384303092956543\n",
      "step_num: 1 -- epoch: 415 -- lr: 0.001 -- loss: 0.29349497705698013\n",
      "step_num: 1 -- epoch: 416 -- lr: 0.001 -- loss: 0.2932493984699249\n",
      "step_num: 1 -- epoch: 417 -- lr: 0.001 -- loss: 0.2933349385857582\n",
      "step_num: 1 -- epoch: 418 -- lr: 0.001 -- loss: 0.2927898168563843\n",
      "step_num: 1 -- epoch: 419 -- lr: 0.001 -- loss: 0.2925732359290123\n",
      "step_num: 1 -- epoch: 420 -- lr: 0.001 -- loss: 0.29231543093919754\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 421 -- lr: 0.001 -- loss: 0.30402688682079315\n",
      "step_num: 1 -- epoch: 422 -- lr: 0.001 -- loss: 0.3022516816854477\n",
      "step_num: 1 -- epoch: 423 -- lr: 0.001 -- loss: 0.3011704981327057\n",
      "step_num: 1 -- epoch: 424 -- lr: 0.001 -- loss: 0.2997135743498802\n",
      "step_num: 1 -- epoch: 425 -- lr: 0.001 -- loss: 0.29911213368177414\n",
      "step_num: 1 -- epoch: 426 -- lr: 0.001 -- loss: 0.298849917948246\n",
      "step_num: 1 -- epoch: 427 -- lr: 0.001 -- loss: 0.2983332574367523\n",
      "step_num: 1 -- epoch: 428 -- lr: 0.001 -- loss: 0.2980981171131134\n",
      "step_num: 1 -- epoch: 429 -- lr: 0.001 -- loss: 0.29762229323387146\n",
      "step_num: 1 -- epoch: 430 -- lr: 0.001 -- loss: 0.29719381779432297\n",
      "step_num: 1 -- epoch: 431 -- lr: 0.001 -- loss: 0.2970668151974678\n",
      "step_num: 1 -- epoch: 432 -- lr: 0.001 -- loss: 0.2968306913971901\n",
      "step_num: 1 -- epoch: 433 -- lr: 0.001 -- loss: 0.2964065745472908\n",
      "step_num: 1 -- epoch: 434 -- lr: 0.001 -- loss: 0.2962767258286476\n",
      "step_num: 1 -- epoch: 435 -- lr: 0.001 -- loss: 0.2960132509469986\n",
      "step_num: 1 -- epoch: 436 -- lr: 0.001 -- loss: 0.29586031287908554\n",
      "step_num: 1 -- epoch: 437 -- lr: 0.001 -- loss: 0.29573771357536316\n",
      "step_num: 1 -- epoch: 438 -- lr: 0.001 -- loss: 0.29522886872291565\n",
      "step_num: 1 -- epoch: 439 -- lr: 0.001 -- loss: 0.2952077239751816\n",
      "step_num: 1 -- epoch: 440 -- lr: 0.001 -- loss: 0.29499049484729767\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 441 -- lr: 0.001 -- loss: 0.2830236554145813\n",
      "step_num: 1 -- epoch: 442 -- lr: 0.001 -- loss: 0.2815077006816864\n",
      "step_num: 1 -- epoch: 443 -- lr: 0.001 -- loss: 0.2796993628144264\n",
      "step_num: 1 -- epoch: 444 -- lr: 0.001 -- loss: 0.27830779552459717\n",
      "step_num: 1 -- epoch: 445 -- lr: 0.001 -- loss: 0.2777849808335304\n",
      "step_num: 1 -- epoch: 446 -- lr: 0.001 -- loss: 0.27772681415081024\n",
      "step_num: 1 -- epoch: 447 -- lr: 0.001 -- loss: 0.277200348675251\n",
      "step_num: 1 -- epoch: 448 -- lr: 0.001 -- loss: 0.27683380991220474\n",
      "step_num: 1 -- epoch: 449 -- lr: 0.001 -- loss: 0.2762947306036949\n",
      "step_num: 1 -- epoch: 450 -- lr: 0.001 -- loss: 0.2761905714869499\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0018652482 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00553*u_x0_y0*u_x1_y0 - 1.0063*u_x0_y1*v_x0_y0 + 0.0593462*u_x0_y2 + 0.060029*u_x2_y0 - 0.0199699\n",
      "derivative of v:  0.0258334*u_x0_y0**2 - 1.0065*u_x0_y0*v_x1_y0 + 0.0307018*v_x0_y0**2 - 1.00612*v_x0_y0*v_x0_y1 + 0.00756941*v_x0_y1**2 + 0.0581606*v_x0_y2 + 0.00803339*v_x1_y0**2 + 0.0594819*v_x2_y0 - 0.157918\n",
      "step_num: 1 -- epoch: 451 -- lr: 0.001 -- loss: 0.2757558226585388\n",
      "step_num: 1 -- epoch: 452 -- lr: 0.001 -- loss: 0.27556760609149933\n",
      "step_num: 1 -- epoch: 453 -- lr: 0.001 -- loss: 0.2753385603427887\n",
      "step_num: 1 -- epoch: 454 -- lr: 0.001 -- loss: 0.2752028927206993\n",
      "step_num: 1 -- epoch: 455 -- lr: 0.001 -- loss: 0.2750149667263031\n",
      "step_num: 1 -- epoch: 456 -- lr: 0.001 -- loss: 0.27493616938591003\n",
      "step_num: 1 -- epoch: 457 -- lr: 0.001 -- loss: 0.27465440332889557\n",
      "step_num: 1 -- epoch: 458 -- lr: 0.001 -- loss: 0.2745539993047714\n",
      "step_num: 1 -- epoch: 459 -- lr: 0.001 -- loss: 0.2743627429008484\n",
      "step_num: 1 -- epoch: 460 -- lr: 0.001 -- loss: 0.27421432733535767\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 461 -- lr: 0.001 -- loss: 0.3161388337612152\n",
      "step_num: 1 -- epoch: 462 -- lr: 0.001 -- loss: 0.30415258556604385\n",
      "step_num: 1 -- epoch: 463 -- lr: 0.001 -- loss: 0.2967885285615921\n",
      "step_num: 1 -- epoch: 464 -- lr: 0.001 -- loss: 0.29412243515253067\n",
      "step_num: 1 -- epoch: 465 -- lr: 0.001 -- loss: 0.29335658997297287\n",
      "step_num: 1 -- epoch: 466 -- lr: 0.001 -- loss: 0.29309647530317307\n",
      "step_num: 1 -- epoch: 467 -- lr: 0.001 -- loss: 0.29260873049497604\n",
      "step_num: 1 -- epoch: 468 -- lr: 0.001 -- loss: 0.2913123667240143\n",
      "step_num: 1 -- epoch: 469 -- lr: 0.001 -- loss: 0.29058240354061127\n",
      "step_num: 1 -- epoch: 470 -- lr: 0.001 -- loss: 0.29025621712207794\n",
      "step_num: 1 -- epoch: 471 -- lr: 0.001 -- loss: 0.28996342420578003\n",
      "step_num: 1 -- epoch: 472 -- lr: 0.001 -- loss: 0.2896197810769081\n",
      "step_num: 1 -- epoch: 473 -- lr: 0.001 -- loss: 0.2896185517311096\n",
      "step_num: 1 -- epoch: 474 -- lr: 0.001 -- loss: 0.28933826088905334\n",
      "step_num: 1 -- epoch: 475 -- lr: 0.001 -- loss: 0.289147213101387\n",
      "step_num: 1 -- epoch: 476 -- lr: 0.001 -- loss: 0.28893908113241196\n",
      "step_num: 1 -- epoch: 477 -- lr: 0.001 -- loss: 0.28893451392650604\n",
      "step_num: 1 -- epoch: 478 -- lr: 0.001 -- loss: 0.28882715851068497\n",
      "step_num: 1 -- epoch: 479 -- lr: 0.001 -- loss: 0.28867097944021225\n",
      "step_num: 1 -- epoch: 480 -- lr: 0.001 -- loss: 0.28870927542448044\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 481 -- lr: 0.001 -- loss: 0.29544053226709366\n",
      "step_num: 1 -- epoch: 482 -- lr: 0.001 -- loss: 0.28820010274648666\n",
      "step_num: 1 -- epoch: 483 -- lr: 0.001 -- loss: 0.28113260120153427\n",
      "step_num: 1 -- epoch: 484 -- lr: 0.001 -- loss: 0.2780313566327095\n",
      "step_num: 1 -- epoch: 485 -- lr: 0.001 -- loss: 0.27595774829387665\n",
      "step_num: 1 -- epoch: 486 -- lr: 0.001 -- loss: 0.2760121449828148\n",
      "step_num: 1 -- epoch: 487 -- lr: 0.001 -- loss: 0.2759503200650215\n",
      "step_num: 1 -- epoch: 488 -- lr: 0.001 -- loss: 0.2755891978740692\n",
      "step_num: 1 -- epoch: 489 -- lr: 0.001 -- loss: 0.27489911019802094\n",
      "step_num: 1 -- epoch: 490 -- lr: 0.001 -- loss: 0.27429434657096863\n",
      "step_num: 1 -- epoch: 491 -- lr: 0.001 -- loss: 0.2736305445432663\n",
      "step_num: 1 -- epoch: 492 -- lr: 0.001 -- loss: 0.27338172495365143\n",
      "step_num: 1 -- epoch: 493 -- lr: 0.001 -- loss: 0.2733205482363701\n",
      "step_num: 1 -- epoch: 494 -- lr: 0.001 -- loss: 0.2731945291161537\n",
      "step_num: 1 -- epoch: 495 -- lr: 0.001 -- loss: 0.27324044704437256\n",
      "step_num: 1 -- epoch: 496 -- lr: 0.001 -- loss: 0.2730722874403\n",
      "step_num: 1 -- epoch: 497 -- lr: 0.001 -- loss: 0.2729165256023407\n",
      "step_num: 1 -- epoch: 498 -- lr: 0.001 -- loss: 0.27283650636672974\n",
      "step_num: 1 -- epoch: 499 -- lr: 0.001 -- loss: 0.2724720388650894\n",
      "step_num: 1 -- epoch: 500 -- lr: 0.001 -- loss: 0.2724626287817955\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0014779613 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.0066*u_x0_y0*u_x1_y0 + 0.00515233*u_x0_y0*u_x1_y1 - 1.00844*u_x0_y1*v_x0_y0 + 0.0596991*u_x0_y2 + 0.0584414*u_x2_y0 - 0.0108447\n",
      "derivative of v:  0.0198611*u_x0_y0**2 - 0.00627243*u_x0_y0*v_x0_y0 - 1.00568*u_x0_y0*v_x1_y0 + 0.0070561*u_x0_y0*v_x1_y1 + 0.0222496*v_x0_y0**2 - 1.00554*v_x0_y0*v_x0_y1 - 0.0074271*v_x0_y0 + 0.00865151*v_x0_y1**2 + 0.0596395*v_x0_y2 + 0.00637295*v_x1_y0**2 + 0.0578736*v_x2_y0 - 0.115557\n",
      "step_num: 1 -- epoch: 501 -- lr: 0.001 -- loss: 0.323195680975914\n",
      "step_num: 1 -- epoch: 502 -- lr: 0.001 -- loss: 0.3113764822483063\n",
      "step_num: 1 -- epoch: 503 -- lr: 0.001 -- loss: 0.3015662431716919\n",
      "step_num: 1 -- epoch: 504 -- lr: 0.001 -- loss: 0.2993019297719002\n",
      "step_num: 1 -- epoch: 505 -- lr: 0.001 -- loss: 0.2987132743000984\n",
      "step_num: 1 -- epoch: 506 -- lr: 0.001 -- loss: 0.29898248612880707\n",
      "step_num: 1 -- epoch: 507 -- lr: 0.001 -- loss: 0.29830193519592285\n",
      "step_num: 1 -- epoch: 508 -- lr: 0.001 -- loss: 0.29786764830350876\n",
      "step_num: 1 -- epoch: 509 -- lr: 0.001 -- loss: 0.2967674434185028\n",
      "step_num: 1 -- epoch: 510 -- lr: 0.001 -- loss: 0.2963062822818756\n",
      "step_num: 1 -- epoch: 511 -- lr: 0.001 -- loss: 0.2961147874593735\n",
      "step_num: 1 -- epoch: 512 -- lr: 0.001 -- loss: 0.2959652915596962\n",
      "step_num: 1 -- epoch: 513 -- lr: 0.001 -- loss: 0.2958597466349602\n",
      "step_num: 1 -- epoch: 514 -- lr: 0.001 -- loss: 0.2955784648656845\n",
      "step_num: 1 -- epoch: 515 -- lr: 0.001 -- loss: 0.29553361237049103\n",
      "step_num: 1 -- epoch: 516 -- lr: 0.001 -- loss: 0.29534821957349777\n",
      "step_num: 1 -- epoch: 517 -- lr: 0.001 -- loss: 0.2953720986843109\n",
      "step_num: 1 -- epoch: 518 -- lr: 0.001 -- loss: 0.2952369675040245\n",
      "step_num: 1 -- epoch: 519 -- lr: 0.001 -- loss: 0.29509342461824417\n",
      "step_num: 1 -- epoch: 520 -- lr: 0.001 -- loss: 0.2950875535607338\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 521 -- lr: 0.001 -- loss: 0.30682770907878876\n",
      "step_num: 1 -- epoch: 522 -- lr: 0.001 -- loss: 0.3011634424328804\n",
      "step_num: 1 -- epoch: 523 -- lr: 0.001 -- loss: 0.2949410527944565\n",
      "step_num: 1 -- epoch: 524 -- lr: 0.001 -- loss: 0.2903373911976814\n",
      "step_num: 1 -- epoch: 525 -- lr: 0.001 -- loss: 0.28948280215263367\n",
      "step_num: 1 -- epoch: 526 -- lr: 0.001 -- loss: 0.288677841424942\n",
      "step_num: 1 -- epoch: 527 -- lr: 0.001 -- loss: 0.28805794566869736\n",
      "step_num: 1 -- epoch: 528 -- lr: 0.001 -- loss: 0.2878141477704048\n",
      "step_num: 1 -- epoch: 529 -- lr: 0.001 -- loss: 0.2879659831523895\n",
      "step_num: 1 -- epoch: 530 -- lr: 0.001 -- loss: 0.28715184330940247\n",
      "step_num: 1 -- epoch: 531 -- lr: 0.001 -- loss: 0.2869131416082382\n",
      "step_num: 1 -- epoch: 532 -- lr: 0.001 -- loss: 0.2866479530930519\n",
      "step_num: 1 -- epoch: 533 -- lr: 0.001 -- loss: 0.2865260988473892\n",
      "step_num: 1 -- epoch: 534 -- lr: 0.001 -- loss: 0.28621456027030945\n",
      "step_num: 1 -- epoch: 535 -- lr: 0.001 -- loss: 0.2862563133239746\n",
      "step_num: 1 -- epoch: 536 -- lr: 0.001 -- loss: 0.2861732318997383\n",
      "step_num: 1 -- epoch: 537 -- lr: 0.001 -- loss: 0.2858571410179138\n",
      "step_num: 1 -- epoch: 538 -- lr: 0.001 -- loss: 0.2860676944255829\n",
      "step_num: 1 -- epoch: 539 -- lr: 0.001 -- loss: 0.28578075766563416\n",
      "step_num: 1 -- epoch: 540 -- lr: 0.001 -- loss: 0.28578878194093704\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 541 -- lr: 0.001 -- loss: 0.2860330268740654\n",
      "step_num: 1 -- epoch: 542 -- lr: 0.001 -- loss: 0.2841310426592827\n",
      "step_num: 1 -- epoch: 543 -- lr: 0.001 -- loss: 0.28308558464050293\n",
      "step_num: 1 -- epoch: 544 -- lr: 0.001 -- loss: 0.2817382141947746\n",
      "step_num: 1 -- epoch: 545 -- lr: 0.001 -- loss: 0.28126420825719833\n",
      "step_num: 1 -- epoch: 546 -- lr: 0.001 -- loss: 0.28083354979753494\n",
      "step_num: 1 -- epoch: 547 -- lr: 0.001 -- loss: 0.28063539415597916\n",
      "step_num: 1 -- epoch: 548 -- lr: 0.001 -- loss: 0.28050631284713745\n",
      "step_num: 1 -- epoch: 549 -- lr: 0.001 -- loss: 0.28049901127815247\n",
      "step_num: 1 -- epoch: 550 -- lr: 0.001 -- loss: 0.28027109801769257\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0016006397 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00648*u_x0_y0*u_x1_y0 - 1.00573*u_x0_y1*v_x0_y0 + 0.0603806*u_x0_y2 + 0.0602777*u_x2_y0 - 0.00644798\n",
      "derivative of v:  0.0136306*u_x0_y0**2 - 1.0066*u_x0_y0*v_x1_y0 + 0.0155409*v_x0_y0**2 - 1.00487*v_x0_y0*v_x0_y1 + 0.0578817*v_x0_y2 + 0.0603188*v_x2_y0 - 0.080802\n",
      "step_num: 1 -- epoch: 551 -- lr: 0.001 -- loss: 0.2803627923130989\n",
      "step_num: 1 -- epoch: 552 -- lr: 0.001 -- loss: 0.28006069362163544\n",
      "step_num: 1 -- epoch: 553 -- lr: 0.001 -- loss: 0.28003523498773575\n",
      "step_num: 1 -- epoch: 554 -- lr: 0.001 -- loss: 0.2799106240272522\n",
      "step_num: 1 -- epoch: 555 -- lr: 0.001 -- loss: 0.27993251383304596\n",
      "step_num: 1 -- epoch: 556 -- lr: 0.001 -- loss: 0.2798605188727379\n",
      "step_num: 1 -- epoch: 557 -- lr: 0.001 -- loss: 0.2797314450144768\n",
      "step_num: 1 -- epoch: 558 -- lr: 0.001 -- loss: 0.2797310799360275\n",
      "step_num: 1 -- epoch: 559 -- lr: 0.001 -- loss: 0.27972202003002167\n",
      "step_num: 1 -- epoch: 560 -- lr: 0.001 -- loss: 0.27970457077026367\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 561 -- lr: 0.001 -- loss: 0.2810242101550102\n",
      "step_num: 1 -- epoch: 562 -- lr: 0.001 -- loss: 0.2795293927192688\n",
      "step_num: 1 -- epoch: 563 -- lr: 0.001 -- loss: 0.2785302400588989\n",
      "step_num: 1 -- epoch: 564 -- lr: 0.001 -- loss: 0.27771034091711044\n",
      "step_num: 1 -- epoch: 565 -- lr: 0.001 -- loss: 0.27715232223272324\n",
      "step_num: 1 -- epoch: 566 -- lr: 0.001 -- loss: 0.2769387438893318\n",
      "step_num: 1 -- epoch: 567 -- lr: 0.001 -- loss: 0.27682627737522125\n",
      "step_num: 1 -- epoch: 568 -- lr: 0.001 -- loss: 0.27658073604106903\n",
      "step_num: 1 -- epoch: 569 -- lr: 0.001 -- loss: 0.2764965742826462\n",
      "step_num: 1 -- epoch: 570 -- lr: 0.001 -- loss: 0.2764185070991516\n",
      "step_num: 1 -- epoch: 571 -- lr: 0.001 -- loss: 0.2762088105082512\n",
      "step_num: 1 -- epoch: 572 -- lr: 0.001 -- loss: 0.2762767821550369\n",
      "step_num: 1 -- epoch: 573 -- lr: 0.001 -- loss: 0.27623455971479416\n",
      "step_num: 1 -- epoch: 574 -- lr: 0.001 -- loss: 0.27609309554100037\n",
      "step_num: 1 -- epoch: 575 -- lr: 0.001 -- loss: 0.2759894132614136\n",
      "step_num: 1 -- epoch: 576 -- lr: 0.001 -- loss: 0.27601978927850723\n",
      "step_num: 1 -- epoch: 577 -- lr: 0.001 -- loss: 0.2759730890393257\n",
      "step_num: 1 -- epoch: 578 -- lr: 0.001 -- loss: 0.2761918902397156\n",
      "step_num: 1 -- epoch: 579 -- lr: 0.001 -- loss: 0.2760706916451454\n",
      "step_num: 1 -- epoch: 580 -- lr: 0.001 -- loss: 0.2759392783045769\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 581 -- lr: 0.001 -- loss: 0.2846202999353409\n",
      "step_num: 1 -- epoch: 582 -- lr: 0.001 -- loss: 0.2819758355617523\n",
      "step_num: 1 -- epoch: 583 -- lr: 0.001 -- loss: 0.2799753099679947\n",
      "step_num: 1 -- epoch: 584 -- lr: 0.001 -- loss: 0.27769579738378525\n",
      "step_num: 1 -- epoch: 585 -- lr: 0.001 -- loss: 0.2778221294283867\n",
      "step_num: 1 -- epoch: 586 -- lr: 0.001 -- loss: 0.2774049863219261\n",
      "step_num: 1 -- epoch: 587 -- lr: 0.001 -- loss: 0.27708927541971207\n",
      "step_num: 1 -- epoch: 588 -- lr: 0.001 -- loss: 0.277006171643734\n",
      "step_num: 1 -- epoch: 589 -- lr: 0.001 -- loss: 0.2767929285764694\n",
      "step_num: 1 -- epoch: 590 -- lr: 0.001 -- loss: 0.2767254263162613\n",
      "step_num: 1 -- epoch: 591 -- lr: 0.001 -- loss: 0.2764996811747551\n",
      "step_num: 1 -- epoch: 592 -- lr: 0.001 -- loss: 0.27644895762205124\n",
      "step_num: 1 -- epoch: 593 -- lr: 0.001 -- loss: 0.2762160301208496\n",
      "step_num: 1 -- epoch: 594 -- lr: 0.001 -- loss: 0.2761361375451088\n",
      "step_num: 1 -- epoch: 595 -- lr: 0.001 -- loss: 0.2762036398053169\n",
      "step_num: 1 -- epoch: 596 -- lr: 0.001 -- loss: 0.2762816697359085\n",
      "step_num: 1 -- epoch: 597 -- lr: 0.001 -- loss: 0.2760668024420738\n",
      "step_num: 1 -- epoch: 598 -- lr: 0.001 -- loss: 0.2760336697101593\n",
      "step_num: 1 -- epoch: 599 -- lr: 0.001 -- loss: 0.2760683372616768\n",
      "step_num: 1 -- epoch: 600 -- lr: 0.001 -- loss: 0.2759125903248787\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0013974926 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00498*u_x0_y0*u_x1_y0 - 1.00608*u_x0_y1*v_x0_y0 + 0.0569555*u_x0_y2 + 0.0623491*u_x2_y0\n",
      "derivative of v:  0.00822781*u_x0_y0**2 - 1.00616*u_x0_y0*v_x1_y0 + 0.00898055*v_x0_y0**2 - 1.00494*v_x0_y0*v_x0_y1 + 0.00822073*v_x0_y0 + 0.0576929*v_x0_y2 + 0.0616101*v_x2_y0 - 0.055946\n",
      "step_num: 1 -- epoch: 601 -- lr: 0.001 -- loss: 0.28186918795108795\n",
      "step_num: 1 -- epoch: 602 -- lr: 0.001 -- loss: 0.27910131961107254\n",
      "step_num: 1 -- epoch: 603 -- lr: 0.001 -- loss: 0.27678483724594116\n",
      "step_num: 1 -- epoch: 604 -- lr: 0.001 -- loss: 0.27591492235660553\n",
      "step_num: 1 -- epoch: 605 -- lr: 0.001 -- loss: 0.2752237915992737\n",
      "step_num: 1 -- epoch: 606 -- lr: 0.001 -- loss: 0.2750798165798187\n",
      "step_num: 1 -- epoch: 607 -- lr: 0.001 -- loss: 0.27493226528167725\n",
      "step_num: 1 -- epoch: 608 -- lr: 0.001 -- loss: 0.274822361767292\n",
      "step_num: 1 -- epoch: 609 -- lr: 0.001 -- loss: 0.2747898995876312\n",
      "step_num: 1 -- epoch: 610 -- lr: 0.001 -- loss: 0.27473433315753937\n",
      "step_num: 1 -- epoch: 611 -- lr: 0.001 -- loss: 0.27445661276578903\n",
      "step_num: 1 -- epoch: 612 -- lr: 0.001 -- loss: 0.27424240857362747\n",
      "step_num: 1 -- epoch: 613 -- lr: 0.001 -- loss: 0.27418453991413116\n",
      "step_num: 1 -- epoch: 614 -- lr: 0.001 -- loss: 0.2741914987564087\n",
      "step_num: 1 -- epoch: 615 -- lr: 0.001 -- loss: 0.27419324219226837\n",
      "step_num: 1 -- epoch: 616 -- lr: 0.001 -- loss: 0.2740759626030922\n",
      "step_num: 1 -- epoch: 617 -- lr: 0.001 -- loss: 0.27410248667001724\n",
      "step_num: 1 -- epoch: 618 -- lr: 0.001 -- loss: 0.27412406355142593\n",
      "step_num: 1 -- epoch: 619 -- lr: 0.001 -- loss: 0.2739991545677185\n",
      "step_num: 1 -- epoch: 620 -- lr: 0.001 -- loss: 0.274042546749115\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 621 -- lr: 0.001 -- loss: 0.2904445677995682\n",
      "step_num: 1 -- epoch: 622 -- lr: 0.001 -- loss: 0.28745653480291367\n",
      "step_num: 1 -- epoch: 623 -- lr: 0.001 -- loss: 0.2853076681494713\n",
      "step_num: 1 -- epoch: 624 -- lr: 0.001 -- loss: 0.2841246649622917\n",
      "step_num: 1 -- epoch: 625 -- lr: 0.001 -- loss: 0.2832292541861534\n",
      "step_num: 1 -- epoch: 626 -- lr: 0.001 -- loss: 0.2825839892029762\n",
      "step_num: 1 -- epoch: 627 -- lr: 0.001 -- loss: 0.2821172624826431\n",
      "step_num: 1 -- epoch: 628 -- lr: 0.001 -- loss: 0.28293442726135254\n",
      "step_num: 1 -- epoch: 629 -- lr: 0.001 -- loss: 0.28244274109601974\n",
      "step_num: 1 -- epoch: 630 -- lr: 0.001 -- loss: 0.2820439636707306\n",
      "step_num: 1 -- epoch: 631 -- lr: 0.001 -- loss: 0.28180962800979614\n",
      "step_num: 1 -- epoch: 632 -- lr: 0.001 -- loss: 0.2818494960665703\n",
      "step_num: 1 -- epoch: 633 -- lr: 0.001 -- loss: 0.2816470041871071\n",
      "step_num: 1 -- epoch: 634 -- lr: 0.001 -- loss: 0.28169384598731995\n",
      "step_num: 1 -- epoch: 635 -- lr: 0.001 -- loss: 0.2815658524632454\n",
      "step_num: 1 -- epoch: 636 -- lr: 0.001 -- loss: 0.2815867066383362\n",
      "step_num: 1 -- epoch: 637 -- lr: 0.001 -- loss: 0.28141699731349945\n",
      "step_num: 1 -- epoch: 638 -- lr: 0.001 -- loss: 0.28143560141324997\n",
      "step_num: 1 -- epoch: 639 -- lr: 0.001 -- loss: 0.2817969471216202\n",
      "step_num: 1 -- epoch: 640 -- lr: 0.001 -- loss: 0.28159038722515106\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 641 -- lr: 0.001 -- loss: 0.29855765402317047\n",
      "step_num: 1 -- epoch: 642 -- lr: 0.001 -- loss: 0.2970593497157097\n",
      "step_num: 1 -- epoch: 643 -- lr: 0.001 -- loss: 0.2934190258383751\n",
      "step_num: 1 -- epoch: 644 -- lr: 0.001 -- loss: 0.2920219823718071\n",
      "step_num: 1 -- epoch: 645 -- lr: 0.001 -- loss: 0.29094862192869186\n",
      "step_num: 1 -- epoch: 646 -- lr: 0.001 -- loss: 0.2908582463860512\n",
      "step_num: 1 -- epoch: 647 -- lr: 0.001 -- loss: 0.2906421273946762\n",
      "step_num: 1 -- epoch: 648 -- lr: 0.001 -- loss: 0.29099713265895844\n",
      "step_num: 1 -- epoch: 649 -- lr: 0.001 -- loss: 0.2904551923274994\n",
      "step_num: 1 -- epoch: 650 -- lr: 0.001 -- loss: 0.2907857373356819\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0013851102 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00634*u_x0_y0*u_x1_y0 - 1.00618*u_x0_y1*v_x0_y0 + 0.061417*u_x0_y2 + 0.0607374*u_x2_y0\n",
      "derivative of v:  0.00646187*u_x0_y0**2 - 1.00702*u_x0_y0*v_x1_y0 + 0.00589687*v_x0_y0**2 - 1.00701*v_x0_y0*v_x0_y1 + 0.061195*v_x0_y2 + 0.0620716*v_x2_y0 - 0.0344365\n",
      "step_num: 1 -- epoch: 651 -- lr: 0.001 -- loss: 0.2904711291193962\n",
      "step_num: 1 -- epoch: 652 -- lr: 0.001 -- loss: 0.2903608903288841\n",
      "step_num: 1 -- epoch: 653 -- lr: 0.001 -- loss: 0.29021093994379044\n",
      "step_num: 1 -- epoch: 654 -- lr: 0.001 -- loss: 0.2906370759010315\n",
      "step_num: 1 -- epoch: 655 -- lr: 0.001 -- loss: 0.29021378606557846\n",
      "step_num: 1 -- epoch: 656 -- lr: 0.001 -- loss: 0.28989972174167633\n",
      "step_num: 1 -- epoch: 657 -- lr: 0.001 -- loss: 0.2900130823254585\n",
      "step_num: 1 -- epoch: 658 -- lr: 0.001 -- loss: 0.2899123579263687\n",
      "step_num: 1 -- epoch: 659 -- lr: 0.001 -- loss: 0.2902347072958946\n",
      "step_num: 1 -- epoch: 660 -- lr: 0.001 -- loss: 0.2900392711162567\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 661 -- lr: 0.001 -- loss: 0.2714432328939438\n",
      "step_num: 1 -- epoch: 662 -- lr: 0.001 -- loss: 0.2707245200872421\n",
      "step_num: 1 -- epoch: 663 -- lr: 0.001 -- loss: 0.2699657380580902\n",
      "step_num: 1 -- epoch: 664 -- lr: 0.001 -- loss: 0.26941172033548355\n",
      "step_num: 1 -- epoch: 665 -- lr: 0.001 -- loss: 0.2689591944217682\n",
      "step_num: 1 -- epoch: 666 -- lr: 0.001 -- loss: 0.268762543797493\n",
      "step_num: 1 -- epoch: 667 -- lr: 0.001 -- loss: 0.2686385065317154\n",
      "step_num: 1 -- epoch: 668 -- lr: 0.001 -- loss: 0.2684624120593071\n",
      "step_num: 1 -- epoch: 669 -- lr: 0.001 -- loss: 0.2684086859226227\n",
      "step_num: 1 -- epoch: 670 -- lr: 0.001 -- loss: 0.2682761251926422\n",
      "step_num: 1 -- epoch: 671 -- lr: 0.001 -- loss: 0.26828180253505707\n",
      "step_num: 1 -- epoch: 672 -- lr: 0.001 -- loss: 0.2683468237519264\n",
      "step_num: 1 -- epoch: 673 -- lr: 0.001 -- loss: 0.26847268640995026\n",
      "step_num: 1 -- epoch: 674 -- lr: 0.001 -- loss: 0.26826202124357224\n",
      "step_num: 1 -- epoch: 675 -- lr: 0.001 -- loss: 0.26805655658245087\n",
      "step_num: 1 -- epoch: 676 -- lr: 0.001 -- loss: 0.2682156339287758\n",
      "step_num: 1 -- epoch: 677 -- lr: 0.001 -- loss: 0.2680886313319206\n",
      "step_num: 1 -- epoch: 678 -- lr: 0.001 -- loss: 0.2681847885251045\n",
      "step_num: 1 -- epoch: 679 -- lr: 0.001 -- loss: 0.2686277702450752\n",
      "step_num: 1 -- epoch: 680 -- lr: 0.001 -- loss: 0.2680492252111435\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 681 -- lr: 0.001 -- loss: 0.2975827306509018\n",
      "step_num: 1 -- epoch: 682 -- lr: 0.001 -- loss: 0.2941145896911621\n",
      "step_num: 1 -- epoch: 683 -- lr: 0.001 -- loss: 0.291111059486866\n",
      "step_num: 1 -- epoch: 684 -- lr: 0.001 -- loss: 0.2890869900584221\n",
      "step_num: 1 -- epoch: 685 -- lr: 0.001 -- loss: 0.2888028621673584\n",
      "step_num: 1 -- epoch: 686 -- lr: 0.001 -- loss: 0.2881498485803604\n",
      "step_num: 1 -- epoch: 687 -- lr: 0.001 -- loss: 0.2880607694387436\n",
      "step_num: 1 -- epoch: 688 -- lr: 0.001 -- loss: 0.28775281459093094\n",
      "step_num: 1 -- epoch: 689 -- lr: 0.001 -- loss: 0.2876122370362282\n",
      "step_num: 1 -- epoch: 690 -- lr: 0.001 -- loss: 0.2875131368637085\n",
      "step_num: 1 -- epoch: 691 -- lr: 0.001 -- loss: 0.28730978071689606\n",
      "step_num: 1 -- epoch: 692 -- lr: 0.001 -- loss: 0.2873300611972809\n",
      "step_num: 1 -- epoch: 693 -- lr: 0.001 -- loss: 0.28730611503124237\n",
      "step_num: 1 -- epoch: 694 -- lr: 0.001 -- loss: 0.28733736276626587\n",
      "step_num: 1 -- epoch: 695 -- lr: 0.001 -- loss: 0.28704819828271866\n",
      "step_num: 1 -- epoch: 696 -- lr: 0.001 -- loss: 0.2873768210411072\n",
      "step_num: 1 -- epoch: 697 -- lr: 0.001 -- loss: 0.28712235391139984\n",
      "step_num: 1 -- epoch: 698 -- lr: 0.001 -- loss: 0.2870286703109741\n",
      "step_num: 1 -- epoch: 699 -- lr: 0.001 -- loss: 0.286888062953949\n",
      "step_num: 1 -- epoch: 700 -- lr: 0.001 -- loss: 0.28684085607528687\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0015105511 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00651*u_x0_y0*u_x1_y0 - 1.00567*u_x0_y1*v_x0_y0 + 0.0619258*u_x0_y2 + 0.0617701*u_x2_y0\n",
      "derivative of v:  -1.00637*u_x0_y0*v_x1_y0 - 1.00441*v_x0_y0*v_x0_y1 + 0.00524502*v_x0_y1*v_x1_y0 + 0.0621938*v_x0_y2 + 0.0610253*v_x2_y0 - 0.0196884\n",
      "step_num: 1 -- epoch: 701 -- lr: 0.001 -- loss: 0.3072652593255043\n",
      "step_num: 1 -- epoch: 702 -- lr: 0.001 -- loss: 0.30279381573200226\n",
      "step_num: 1 -- epoch: 703 -- lr: 0.001 -- loss: 0.29796353727579117\n",
      "step_num: 1 -- epoch: 704 -- lr: 0.001 -- loss: 0.29567166417837143\n",
      "step_num: 1 -- epoch: 705 -- lr: 0.001 -- loss: 0.29523759335279465\n",
      "step_num: 1 -- epoch: 706 -- lr: 0.001 -- loss: 0.29529113322496414\n",
      "step_num: 1 -- epoch: 707 -- lr: 0.001 -- loss: 0.2956515923142433\n",
      "step_num: 1 -- epoch: 708 -- lr: 0.001 -- loss: 0.29558613151311874\n",
      "step_num: 1 -- epoch: 709 -- lr: 0.001 -- loss: 0.29519282281398773\n",
      "step_num: 1 -- epoch: 710 -- lr: 0.001 -- loss: 0.29471733421087265\n",
      "step_num: 1 -- epoch: 711 -- lr: 0.001 -- loss: 0.29434049874544144\n",
      "step_num: 1 -- epoch: 712 -- lr: 0.001 -- loss: 0.2948165014386177\n",
      "step_num: 1 -- epoch: 713 -- lr: 0.001 -- loss: 0.29453258216381073\n",
      "step_num: 1 -- epoch: 714 -- lr: 0.001 -- loss: 0.29448066651821136\n",
      "step_num: 1 -- epoch: 715 -- lr: 0.001 -- loss: 0.2943182587623596\n",
      "step_num: 1 -- epoch: 716 -- lr: 0.001 -- loss: 0.2943204417824745\n",
      "step_num: 1 -- epoch: 717 -- lr: 0.001 -- loss: 0.29425184428691864\n",
      "step_num: 1 -- epoch: 718 -- lr: 0.001 -- loss: 0.2943182662129402\n",
      "step_num: 1 -- epoch: 719 -- lr: 0.001 -- loss: 0.2941747382283211\n",
      "step_num: 1 -- epoch: 720 -- lr: 0.001 -- loss: 0.29456616193056107\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 721 -- lr: 0.001 -- loss: 0.30331938713788986\n",
      "step_num: 1 -- epoch: 722 -- lr: 0.001 -- loss: 0.29225607961416245\n",
      "step_num: 1 -- epoch: 723 -- lr: 0.001 -- loss: 0.285039983689785\n",
      "step_num: 1 -- epoch: 724 -- lr: 0.001 -- loss: 0.2817544937133789\n",
      "step_num: 1 -- epoch: 725 -- lr: 0.001 -- loss: 0.28059180080890656\n",
      "step_num: 1 -- epoch: 726 -- lr: 0.001 -- loss: 0.27970926463603973\n",
      "step_num: 1 -- epoch: 727 -- lr: 0.001 -- loss: 0.27978888899087906\n",
      "step_num: 1 -- epoch: 728 -- lr: 0.001 -- loss: 0.2800610288977623\n",
      "step_num: 1 -- epoch: 729 -- lr: 0.001 -- loss: 0.27935656160116196\n",
      "step_num: 1 -- epoch: 730 -- lr: 0.001 -- loss: 0.278808169066906\n",
      "step_num: 1 -- epoch: 731 -- lr: 0.001 -- loss: 0.2784026339650154\n",
      "step_num: 1 -- epoch: 732 -- lr: 0.001 -- loss: 0.27835461497306824\n",
      "step_num: 1 -- epoch: 733 -- lr: 0.001 -- loss: 0.2782474309206009\n",
      "step_num: 1 -- epoch: 734 -- lr: 0.001 -- loss: 0.2781298905611038\n",
      "step_num: 1 -- epoch: 735 -- lr: 0.001 -- loss: 0.2780385836958885\n",
      "step_num: 1 -- epoch: 736 -- lr: 0.001 -- loss: 0.2780844271183014\n",
      "step_num: 1 -- epoch: 737 -- lr: 0.001 -- loss: 0.2780088111758232\n",
      "step_num: 1 -- epoch: 738 -- lr: 0.001 -- loss: 0.27793270349502563\n",
      "step_num: 1 -- epoch: 739 -- lr: 0.001 -- loss: 0.27806488424539566\n",
      "step_num: 1 -- epoch: 740 -- lr: 0.001 -- loss: 0.27785222977399826\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 741 -- lr: 0.001 -- loss: 0.29386257380247116\n",
      "step_num: 1 -- epoch: 742 -- lr: 0.001 -- loss: 0.2850206792354584\n",
      "step_num: 1 -- epoch: 743 -- lr: 0.001 -- loss: 0.27608900517225266\n",
      "step_num: 1 -- epoch: 744 -- lr: 0.001 -- loss: 0.27390845865011215\n",
      "step_num: 1 -- epoch: 745 -- lr: 0.001 -- loss: 0.27249041199684143\n",
      "step_num: 1 -- epoch: 746 -- lr: 0.001 -- loss: 0.272088922560215\n",
      "step_num: 1 -- epoch: 747 -- lr: 0.001 -- loss: 0.2717301845550537\n",
      "step_num: 1 -- epoch: 748 -- lr: 0.001 -- loss: 0.27176523208618164\n",
      "step_num: 1 -- epoch: 749 -- lr: 0.001 -- loss: 0.27095071971416473\n",
      "step_num: 1 -- epoch: 750 -- lr: 0.001 -- loss: 0.27047212421894073\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0015112034 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00663*u_x0_y0*u_x1_y0 + 0.00864053*u_x0_y0 - 1.00531*u_x0_y1*v_x0_y0 - 0.00652316*u_x0_y1*v_x1_y0 + 0.0580294*u_x0_y2 - 0.00777823*u_x1_y1*v_x0_y0 + 0.0574121*u_x2_y0 - 0.00511313\n",
      "derivative of v:  -1.0058*u_x0_y0*v_x1_y0 - 0.00648095*u_x1_y0*v_x1_y0 - 1.00662*v_x0_y0*v_x0_y1 - 0.00615078*v_x0_y0*v_x1_y1 - 0.00657806*v_x0_y1*v_x1_y0 + 0.059072*v_x0_y2 + 0.0563702*v_x2_y0 - 0.0101086\n",
      "step_num: 1 -- epoch: 751 -- lr: 0.001 -- loss: 0.27011535316705704\n",
      "step_num: 1 -- epoch: 752 -- lr: 0.001 -- loss: 0.26979029178619385\n",
      "step_num: 1 -- epoch: 753 -- lr: 0.001 -- loss: 0.26973436772823334\n",
      "step_num: 1 -- epoch: 754 -- lr: 0.001 -- loss: 0.2699424624443054\n",
      "step_num: 1 -- epoch: 755 -- lr: 0.001 -- loss: 0.26968228071928024\n",
      "step_num: 1 -- epoch: 756 -- lr: 0.001 -- loss: 0.26979774981737137\n",
      "step_num: 1 -- epoch: 757 -- lr: 0.001 -- loss: 0.26960016787052155\n",
      "step_num: 1 -- epoch: 758 -- lr: 0.001 -- loss: 0.2696562334895134\n",
      "step_num: 1 -- epoch: 759 -- lr: 0.001 -- loss: 0.26956676691770554\n",
      "step_num: 1 -- epoch: 760 -- lr: 0.001 -- loss: 0.269609734416008\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 761 -- lr: 0.001 -- loss: 0.2896023243665695\n",
      "step_num: 1 -- epoch: 762 -- lr: 0.001 -- loss: 0.2856794074177742\n",
      "step_num: 1 -- epoch: 763 -- lr: 0.001 -- loss: 0.2833361476659775\n",
      "step_num: 1 -- epoch: 764 -- lr: 0.001 -- loss: 0.28232821822166443\n",
      "step_num: 1 -- epoch: 765 -- lr: 0.001 -- loss: 0.28080376982688904\n",
      "step_num: 1 -- epoch: 766 -- lr: 0.001 -- loss: 0.28040575981140137\n",
      "step_num: 1 -- epoch: 767 -- lr: 0.001 -- loss: 0.27991318702697754\n",
      "step_num: 1 -- epoch: 768 -- lr: 0.001 -- loss: 0.27976347506046295\n",
      "step_num: 1 -- epoch: 769 -- lr: 0.001 -- loss: 0.27964843809604645\n",
      "step_num: 1 -- epoch: 770 -- lr: 0.001 -- loss: 0.2796219736337662\n",
      "step_num: 1 -- epoch: 771 -- lr: 0.001 -- loss: 0.27964651584625244\n",
      "step_num: 1 -- epoch: 772 -- lr: 0.001 -- loss: 0.27939677238464355\n",
      "step_num: 1 -- epoch: 773 -- lr: 0.001 -- loss: 0.2793738767504692\n",
      "step_num: 1 -- epoch: 774 -- lr: 0.001 -- loss: 0.2794526070356369\n",
      "step_num: 1 -- epoch: 775 -- lr: 0.001 -- loss: 0.27920713275671005\n",
      "step_num: 1 -- epoch: 776 -- lr: 0.001 -- loss: 0.27936839312314987\n",
      "step_num: 1 -- epoch: 777 -- lr: 0.001 -- loss: 0.2793765515089035\n",
      "step_num: 1 -- epoch: 778 -- lr: 0.001 -- loss: 0.2791939750313759\n",
      "step_num: 1 -- epoch: 779 -- lr: 0.001 -- loss: 0.27925074845552444\n",
      "step_num: 1 -- epoch: 780 -- lr: 0.001 -- loss: 0.279381662607193\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 781 -- lr: 0.001 -- loss: 0.27381284534931183\n",
      "step_num: 1 -- epoch: 782 -- lr: 0.001 -- loss: 0.2730135917663574\n",
      "step_num: 1 -- epoch: 783 -- lr: 0.001 -- loss: 0.2717636302113533\n",
      "step_num: 1 -- epoch: 784 -- lr: 0.001 -- loss: 0.27152150124311447\n",
      "step_num: 1 -- epoch: 785 -- lr: 0.001 -- loss: 0.2710418701171875\n",
      "step_num: 1 -- epoch: 786 -- lr: 0.001 -- loss: 0.2709115743637085\n",
      "step_num: 1 -- epoch: 787 -- lr: 0.001 -- loss: 0.27072635293006897\n",
      "step_num: 1 -- epoch: 788 -- lr: 0.001 -- loss: 0.2707279101014137\n",
      "step_num: 1 -- epoch: 789 -- lr: 0.001 -- loss: 0.2704009711742401\n",
      "step_num: 1 -- epoch: 790 -- lr: 0.001 -- loss: 0.2706027328968048\n",
      "step_num: 1 -- epoch: 791 -- lr: 0.001 -- loss: 0.270261213183403\n",
      "step_num: 1 -- epoch: 792 -- lr: 0.001 -- loss: 0.270235039293766\n",
      "step_num: 1 -- epoch: 793 -- lr: 0.001 -- loss: 0.27060531079769135\n",
      "step_num: 1 -- epoch: 794 -- lr: 0.001 -- loss: 0.2703438475728035\n",
      "step_num: 1 -- epoch: 795 -- lr: 0.001 -- loss: 0.27052922546863556\n",
      "step_num: 1 -- epoch: 796 -- lr: 0.001 -- loss: 0.27040209621191025\n",
      "step_num: 1 -- epoch: 797 -- lr: 0.001 -- loss: 0.2703709080815315\n",
      "step_num: 1 -- epoch: 798 -- lr: 0.001 -- loss: 0.27030806988477707\n",
      "step_num: 1 -- epoch: 799 -- lr: 0.001 -- loss: 0.2702570855617523\n",
      "step_num: 1 -- epoch: 800 -- lr: 0.001 -- loss: 0.27031462639570236\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0014881793 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00632*u_x0_y0*u_x1_y0 - 1.00588*u_x0_y1*v_x0_y0 + 0.059266*u_x0_y2 + 0.0596798*u_x2_y0\n",
      "derivative of v:  -1.00535*u_x0_y0*v_x1_y0 - 1.0062*v_x0_y0*v_x0_y1 + 0.0591276*v_x0_y2 + 0.0581055*v_x2_y0 - 0.00602563\n",
      "step_num: 1 -- epoch: 801 -- lr: 0.001 -- loss: 0.2894674018025398\n",
      "step_num: 1 -- epoch: 802 -- lr: 0.001 -- loss: 0.2876858413219452\n",
      "step_num: 1 -- epoch: 803 -- lr: 0.001 -- loss: 0.28536999225616455\n",
      "step_num: 1 -- epoch: 804 -- lr: 0.001 -- loss: 0.28476860374212265\n",
      "step_num: 1 -- epoch: 805 -- lr: 0.001 -- loss: 0.2842322736978531\n",
      "step_num: 1 -- epoch: 806 -- lr: 0.001 -- loss: 0.2840694263577461\n",
      "step_num: 1 -- epoch: 807 -- lr: 0.001 -- loss: 0.2841509282588959\n",
      "step_num: 1 -- epoch: 808 -- lr: 0.001 -- loss: 0.2839115932583809\n",
      "step_num: 1 -- epoch: 809 -- lr: 0.001 -- loss: 0.2838510125875473\n",
      "step_num: 1 -- epoch: 810 -- lr: 0.001 -- loss: 0.28374604880809784\n",
      "step_num: 1 -- epoch: 811 -- lr: 0.001 -- loss: 0.28372110426425934\n",
      "step_num: 1 -- epoch: 812 -- lr: 0.001 -- loss: 0.2836492732167244\n",
      "step_num: 1 -- epoch: 813 -- lr: 0.001 -- loss: 0.28364239633083344\n",
      "step_num: 1 -- epoch: 814 -- lr: 0.001 -- loss: 0.2836901992559433\n",
      "step_num: 1 -- epoch: 815 -- lr: 0.001 -- loss: 0.2834632247686386\n",
      "step_num: 1 -- epoch: 816 -- lr: 0.001 -- loss: 0.2834935262799263\n",
      "step_num: 1 -- epoch: 817 -- lr: 0.001 -- loss: 0.28353679925203323\n",
      "step_num: 1 -- epoch: 818 -- lr: 0.001 -- loss: 0.28349218517541885\n",
      "step_num: 1 -- epoch: 819 -- lr: 0.001 -- loss: 0.2834683731198311\n",
      "step_num: 1 -- epoch: 820 -- lr: 0.001 -- loss: 0.2833990603685379\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 821 -- lr: 0.001 -- loss: 0.2863188609480858\n",
      "step_num: 1 -- epoch: 822 -- lr: 0.001 -- loss: 0.28424622118473053\n",
      "step_num: 1 -- epoch: 823 -- lr: 0.001 -- loss: 0.28252239525318146\n",
      "step_num: 1 -- epoch: 824 -- lr: 0.001 -- loss: 0.2812558114528656\n",
      "step_num: 1 -- epoch: 825 -- lr: 0.001 -- loss: 0.28120389580726624\n",
      "step_num: 1 -- epoch: 826 -- lr: 0.001 -- loss: 0.28108765184879303\n",
      "step_num: 1 -- epoch: 827 -- lr: 0.001 -- loss: 0.2810426726937294\n",
      "step_num: 1 -- epoch: 828 -- lr: 0.001 -- loss: 0.28077883273363113\n",
      "step_num: 1 -- epoch: 829 -- lr: 0.001 -- loss: 0.2806899771094322\n",
      "step_num: 1 -- epoch: 830 -- lr: 0.001 -- loss: 0.28038550913333893\n",
      "step_num: 1 -- epoch: 831 -- lr: 0.001 -- loss: 0.2803124785423279\n",
      "step_num: 1 -- epoch: 832 -- lr: 0.001 -- loss: 0.28064971417188644\n",
      "step_num: 1 -- epoch: 833 -- lr: 0.001 -- loss: 0.28044360131025314\n",
      "step_num: 1 -- epoch: 834 -- lr: 0.001 -- loss: 0.28035761415958405\n",
      "step_num: 1 -- epoch: 835 -- lr: 0.001 -- loss: 0.2802569791674614\n",
      "step_num: 1 -- epoch: 836 -- lr: 0.001 -- loss: 0.2804141342639923\n",
      "step_num: 1 -- epoch: 837 -- lr: 0.001 -- loss: 0.2804267406463623\n",
      "step_num: 1 -- epoch: 838 -- lr: 0.001 -- loss: 0.28015775233507156\n",
      "step_num: 1 -- epoch: 839 -- lr: 0.001 -- loss: 0.2801365405321121\n",
      "step_num: 1 -- epoch: 840 -- lr: 0.001 -- loss: 0.28023990988731384\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 841 -- lr: 0.001 -- loss: 0.3203047439455986\n",
      "step_num: 1 -- epoch: 842 -- lr: 0.001 -- loss: 0.31410567462444305\n",
      "step_num: 1 -- epoch: 843 -- lr: 0.001 -- loss: 0.3114599362015724\n",
      "step_num: 1 -- epoch: 844 -- lr: 0.001 -- loss: 0.3099673166871071\n",
      "step_num: 1 -- epoch: 845 -- lr: 0.001 -- loss: 0.30995532125234604\n",
      "step_num: 1 -- epoch: 846 -- lr: 0.001 -- loss: 0.3092144951224327\n",
      "step_num: 1 -- epoch: 847 -- lr: 0.001 -- loss: 0.30912475287914276\n",
      "step_num: 1 -- epoch: 848 -- lr: 0.001 -- loss: 0.3089616969227791\n",
      "step_num: 1 -- epoch: 849 -- lr: 0.001 -- loss: 0.30849628150463104\n",
      "step_num: 1 -- epoch: 850 -- lr: 0.001 -- loss: 0.30845633894205093\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.001447204 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00711*u_x0_y0*u_x1_y0 - 1.00606*u_x0_y1*v_x0_y0 + 0.00634613*u_x0_y1*v_x0_y1 + 0.059395*u_x0_y2 + 0.0603663*u_x2_y0\n",
      "derivative of v:  -1.00419*u_x0_y0*v_x1_y0 - 1.00749*v_x0_y0*v_x0_y1 + 0.00522111*v_x0_y0*v_x0_y2 + 0.0585457*v_x0_y2 + 0.0591388*v_x2_y0\n",
      "step_num: 1 -- epoch: 851 -- lr: 0.001 -- loss: 0.3086955323815346\n",
      "step_num: 1 -- epoch: 852 -- lr: 0.001 -- loss: 0.30814118683338165\n",
      "step_num: 1 -- epoch: 853 -- lr: 0.001 -- loss: 0.30814896523952484\n",
      "step_num: 1 -- epoch: 854 -- lr: 0.001 -- loss: 0.30820754915475845\n",
      "step_num: 1 -- epoch: 855 -- lr: 0.001 -- loss: 0.30820442736148834\n",
      "step_num: 1 -- epoch: 856 -- lr: 0.001 -- loss: 0.3080265671014786\n",
      "step_num: 1 -- epoch: 857 -- lr: 0.001 -- loss: 0.30794964730739594\n",
      "step_num: 1 -- epoch: 858 -- lr: 0.001 -- loss: 0.3080451712012291\n",
      "step_num: 1 -- epoch: 859 -- lr: 0.001 -- loss: 0.30793220549821854\n",
      "step_num: 1 -- epoch: 860 -- lr: 0.001 -- loss: 0.30782975256443024\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 861 -- lr: 0.001 -- loss: 0.3124425411224365\n",
      "step_num: 1 -- epoch: 862 -- lr: 0.001 -- loss: 0.30145663022994995\n",
      "step_num: 1 -- epoch: 863 -- lr: 0.001 -- loss: 0.29299765080213547\n",
      "step_num: 1 -- epoch: 864 -- lr: 0.001 -- loss: 0.29092150181531906\n",
      "step_num: 1 -- epoch: 865 -- lr: 0.001 -- loss: 0.29030393064022064\n",
      "step_num: 1 -- epoch: 866 -- lr: 0.001 -- loss: 0.28911613672971725\n",
      "step_num: 1 -- epoch: 867 -- lr: 0.001 -- loss: 0.28840500861406326\n",
      "step_num: 1 -- epoch: 868 -- lr: 0.001 -- loss: 0.28808240592479706\n",
      "step_num: 1 -- epoch: 869 -- lr: 0.001 -- loss: 0.2880929112434387\n",
      "step_num: 1 -- epoch: 870 -- lr: 0.001 -- loss: 0.2878333330154419\n",
      "step_num: 1 -- epoch: 871 -- lr: 0.001 -- loss: 0.2871371954679489\n",
      "step_num: 1 -- epoch: 872 -- lr: 0.001 -- loss: 0.2871604189276695\n",
      "step_num: 1 -- epoch: 873 -- lr: 0.001 -- loss: 0.2869459018111229\n",
      "step_num: 1 -- epoch: 874 -- lr: 0.001 -- loss: 0.28680089861154556\n",
      "step_num: 1 -- epoch: 875 -- lr: 0.001 -- loss: 0.28673552721738815\n",
      "step_num: 1 -- epoch: 876 -- lr: 0.001 -- loss: 0.28654178977012634\n",
      "step_num: 1 -- epoch: 877 -- lr: 0.001 -- loss: 0.2865658849477768\n",
      "step_num: 1 -- epoch: 878 -- lr: 0.001 -- loss: 0.28653259575366974\n",
      "step_num: 1 -- epoch: 879 -- lr: 0.001 -- loss: 0.2865699529647827\n",
      "step_num: 1 -- epoch: 880 -- lr: 0.001 -- loss: 0.2864815220236778\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 881 -- lr: 0.001 -- loss: 0.30354174971580505\n",
      "step_num: 1 -- epoch: 882 -- lr: 0.001 -- loss: 0.29310309886932373\n",
      "step_num: 1 -- epoch: 883 -- lr: 0.001 -- loss: 0.2834000065922737\n",
      "step_num: 1 -- epoch: 884 -- lr: 0.001 -- loss: 0.2803794592618942\n",
      "step_num: 1 -- epoch: 885 -- lr: 0.001 -- loss: 0.27824508398771286\n",
      "step_num: 1 -- epoch: 886 -- lr: 0.001 -- loss: 0.277468703687191\n",
      "step_num: 1 -- epoch: 887 -- lr: 0.001 -- loss: 0.2770382985472679\n",
      "step_num: 1 -- epoch: 888 -- lr: 0.001 -- loss: 0.2775091379880905\n",
      "step_num: 1 -- epoch: 889 -- lr: 0.001 -- loss: 0.27710893750190735\n",
      "step_num: 1 -- epoch: 890 -- lr: 0.001 -- loss: 0.27663811296224594\n",
      "step_num: 1 -- epoch: 891 -- lr: 0.001 -- loss: 0.27635061740875244\n",
      "step_num: 1 -- epoch: 892 -- lr: 0.001 -- loss: 0.27607980370521545\n",
      "step_num: 1 -- epoch: 893 -- lr: 0.001 -- loss: 0.2761501893401146\n",
      "step_num: 1 -- epoch: 894 -- lr: 0.001 -- loss: 0.2757617011666298\n",
      "step_num: 1 -- epoch: 895 -- lr: 0.001 -- loss: 0.2758253589272499\n",
      "step_num: 1 -- epoch: 896 -- lr: 0.001 -- loss: 0.2756281793117523\n",
      "step_num: 1 -- epoch: 897 -- lr: 0.001 -- loss: 0.2756747528910637\n",
      "step_num: 1 -- epoch: 898 -- lr: 0.001 -- loss: 0.27560513466596603\n",
      "step_num: 1 -- epoch: 899 -- lr: 0.001 -- loss: 0.275515541434288\n",
      "step_num: 1 -- epoch: 900 -- lr: 0.001 -- loss: 0.2757095843553543\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0014723972 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00778*u_x0_y0*u_x1_y0 + 0.00500086*u_x0_y0*u_x1_y1 - 1.00664*u_x0_y1*v_x0_y0 + 0.0604366*u_x0_y2 + 0.0594766*u_x2_y0\n",
      "derivative of v:  -1.00691*u_x0_y0*v_x1_y0 + 0.00658993*u_x0_y0*v_x1_y1 - 1.00346*v_x0_y0*v_x0_y1 + 0.0598795*v_x0_y2 + 0.0615274*v_x2_y0\n",
      "step_num: 1 -- epoch: 901 -- lr: 0.001 -- loss: 0.2882051393389702\n",
      "step_num: 1 -- epoch: 902 -- lr: 0.001 -- loss: 0.2838538810610771\n",
      "step_num: 1 -- epoch: 903 -- lr: 0.001 -- loss: 0.2834271788597107\n",
      "step_num: 1 -- epoch: 904 -- lr: 0.001 -- loss: 0.280326746404171\n",
      "step_num: 1 -- epoch: 905 -- lr: 0.001 -- loss: 0.2790035381913185\n",
      "step_num: 1 -- epoch: 906 -- lr: 0.001 -- loss: 0.2780972495675087\n",
      "step_num: 1 -- epoch: 907 -- lr: 0.001 -- loss: 0.27824655175209045\n",
      "step_num: 1 -- epoch: 908 -- lr: 0.001 -- loss: 0.27796992659568787\n",
      "step_num: 1 -- epoch: 909 -- lr: 0.001 -- loss: 0.2778582125902176\n",
      "step_num: 1 -- epoch: 910 -- lr: 0.001 -- loss: 0.2778637111186981\n",
      "step_num: 1 -- epoch: 911 -- lr: 0.001 -- loss: 0.27762095630168915\n",
      "step_num: 1 -- epoch: 912 -- lr: 0.001 -- loss: 0.278002493083477\n",
      "step_num: 1 -- epoch: 913 -- lr: 0.001 -- loss: 0.2776178643107414\n",
      "step_num: 1 -- epoch: 914 -- lr: 0.001 -- loss: 0.2775178849697113\n",
      "step_num: 1 -- epoch: 915 -- lr: 0.001 -- loss: 0.2773823142051697\n",
      "step_num: 1 -- epoch: 916 -- lr: 0.001 -- loss: 0.2773435190320015\n",
      "step_num: 1 -- epoch: 917 -- lr: 0.001 -- loss: 0.277483768761158\n",
      "step_num: 1 -- epoch: 918 -- lr: 0.001 -- loss: 0.2774733081459999\n",
      "step_num: 1 -- epoch: 919 -- lr: 0.001 -- loss: 0.27726415544748306\n",
      "step_num: 1 -- epoch: 920 -- lr: 0.001 -- loss: 0.2773270308971405\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 921 -- lr: 0.001 -- loss: 0.29409975558519363\n",
      "step_num: 1 -- epoch: 922 -- lr: 0.001 -- loss: 0.2879862114787102\n",
      "step_num: 1 -- epoch: 923 -- lr: 0.001 -- loss: 0.2827267125248909\n",
      "step_num: 1 -- epoch: 924 -- lr: 0.001 -- loss: 0.28116269409656525\n",
      "step_num: 1 -- epoch: 925 -- lr: 0.001 -- loss: 0.27905990928411484\n",
      "step_num: 1 -- epoch: 926 -- lr: 0.001 -- loss: 0.27907565236091614\n",
      "step_num: 1 -- epoch: 927 -- lr: 0.001 -- loss: 0.27851925790309906\n",
      "step_num: 1 -- epoch: 928 -- lr: 0.001 -- loss: 0.27853138744831085\n",
      "step_num: 1 -- epoch: 929 -- lr: 0.001 -- loss: 0.2776670604944229\n",
      "step_num: 1 -- epoch: 930 -- lr: 0.001 -- loss: 0.27713458985090256\n",
      "step_num: 1 -- epoch: 931 -- lr: 0.001 -- loss: 0.27710939943790436\n",
      "step_num: 1 -- epoch: 932 -- lr: 0.001 -- loss: 0.2772732824087143\n",
      "step_num: 1 -- epoch: 933 -- lr: 0.001 -- loss: 0.27700723707675934\n",
      "step_num: 1 -- epoch: 934 -- lr: 0.001 -- loss: 0.27699869126081467\n",
      "step_num: 1 -- epoch: 935 -- lr: 0.001 -- loss: 0.2769899144768715\n",
      "step_num: 1 -- epoch: 936 -- lr: 0.001 -- loss: 0.27720416337251663\n",
      "step_num: 1 -- epoch: 937 -- lr: 0.001 -- loss: 0.2771350219845772\n",
      "step_num: 1 -- epoch: 938 -- lr: 0.001 -- loss: 0.2768741399049759\n",
      "step_num: 1 -- epoch: 939 -- lr: 0.001 -- loss: 0.27697324752807617\n",
      "step_num: 1 -- epoch: 940 -- lr: 0.001 -- loss: 0.27717578411102295\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 941 -- lr: 0.001 -- loss: 0.2907395362854004\n",
      "step_num: 1 -- epoch: 942 -- lr: 0.001 -- loss: 0.2889067083597183\n",
      "step_num: 1 -- epoch: 943 -- lr: 0.001 -- loss: 0.2865922749042511\n",
      "step_num: 1 -- epoch: 944 -- lr: 0.001 -- loss: 0.2855070158839226\n",
      "step_num: 1 -- epoch: 945 -- lr: 0.001 -- loss: 0.2844640910625458\n",
      "step_num: 1 -- epoch: 946 -- lr: 0.001 -- loss: 0.2846021056175232\n",
      "step_num: 1 -- epoch: 947 -- lr: 0.001 -- loss: 0.2846617326140404\n",
      "step_num: 1 -- epoch: 948 -- lr: 0.001 -- loss: 0.2844774052500725\n",
      "step_num: 1 -- epoch: 949 -- lr: 0.001 -- loss: 0.284322552382946\n",
      "step_num: 1 -- epoch: 950 -- lr: 0.001 -- loss: 0.2843761667609215\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0014684501 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00812*u_x0_y0*u_x1_y0 - 1.00662*u_x0_y1*v_x0_y0 + 0.0589606*u_x0_y2 + 0.0604078*u_x2_y0 - 0.0050005\n",
      "derivative of v:  -1.00604*u_x0_y0*v_x1_y0 - 1.00501*v_x0_y0*v_x0_y1 + 0.060094*v_x0_y2 + 0.0586912*v_x2_y0\n",
      "step_num: 1 -- epoch: 951 -- lr: 0.001 -- loss: 0.2843852862715721\n",
      "step_num: 1 -- epoch: 952 -- lr: 0.001 -- loss: 0.2841501832008362\n",
      "step_num: 1 -- epoch: 953 -- lr: 0.001 -- loss: 0.2843300551176071\n",
      "step_num: 1 -- epoch: 954 -- lr: 0.001 -- loss: 0.28403493762016296\n",
      "step_num: 1 -- epoch: 955 -- lr: 0.001 -- loss: 0.2842225879430771\n",
      "step_num: 1 -- epoch: 956 -- lr: 0.001 -- loss: 0.28397852927446365\n",
      "step_num: 1 -- epoch: 957 -- lr: 0.001 -- loss: 0.2839897945523262\n",
      "step_num: 1 -- epoch: 958 -- lr: 0.001 -- loss: 0.28419167548418045\n",
      "step_num: 1 -- epoch: 959 -- lr: 0.001 -- loss: 0.2839965969324112\n",
      "step_num: 1 -- epoch: 960 -- lr: 0.001 -- loss: 0.28413330018520355\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 961 -- lr: 0.001 -- loss: 0.2750895917415619\n",
      "step_num: 1 -- epoch: 962 -- lr: 0.001 -- loss: 0.2715408727526665\n",
      "step_num: 1 -- epoch: 963 -- lr: 0.001 -- loss: 0.2692091763019562\n",
      "step_num: 1 -- epoch: 964 -- lr: 0.001 -- loss: 0.26789434254169464\n",
      "step_num: 1 -- epoch: 965 -- lr: 0.001 -- loss: 0.2675660029053688\n",
      "step_num: 1 -- epoch: 966 -- lr: 0.001 -- loss: 0.2679927423596382\n",
      "step_num: 1 -- epoch: 967 -- lr: 0.001 -- loss: 0.2674904093146324\n",
      "step_num: 1 -- epoch: 968 -- lr: 0.001 -- loss: 0.2673732489347458\n",
      "step_num: 1 -- epoch: 969 -- lr: 0.001 -- loss: 0.26731304824352264\n",
      "step_num: 1 -- epoch: 970 -- lr: 0.001 -- loss: 0.2668604850769043\n",
      "step_num: 1 -- epoch: 971 -- lr: 0.001 -- loss: 0.26707832515239716\n",
      "step_num: 1 -- epoch: 972 -- lr: 0.001 -- loss: 0.26694174110889435\n",
      "step_num: 1 -- epoch: 973 -- lr: 0.001 -- loss: 0.26685796678066254\n",
      "step_num: 1 -- epoch: 974 -- lr: 0.001 -- loss: 0.2668195441365242\n",
      "step_num: 1 -- epoch: 975 -- lr: 0.001 -- loss: 0.26675523072481155\n",
      "step_num: 1 -- epoch: 976 -- lr: 0.001 -- loss: 0.26664045453071594\n",
      "step_num: 1 -- epoch: 977 -- lr: 0.001 -- loss: 0.2666161581873894\n",
      "step_num: 1 -- epoch: 978 -- lr: 0.001 -- loss: 0.2667339965701103\n",
      "step_num: 1 -- epoch: 979 -- lr: 0.001 -- loss: 0.2667416110634804\n",
      "step_num: 1 -- epoch: 980 -- lr: 0.001 -- loss: 0.26711830496788025\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 981 -- lr: 0.001 -- loss: 0.28437290340662\n",
      "step_num: 1 -- epoch: 982 -- lr: 0.001 -- loss: 0.2809421643614769\n",
      "step_num: 1 -- epoch: 983 -- lr: 0.001 -- loss: 0.27820275723934174\n",
      "step_num: 1 -- epoch: 984 -- lr: 0.001 -- loss: 0.2779976353049278\n",
      "step_num: 1 -- epoch: 985 -- lr: 0.001 -- loss: 0.27696989476680756\n",
      "step_num: 1 -- epoch: 986 -- lr: 0.001 -- loss: 0.2764565572142601\n",
      "step_num: 1 -- epoch: 987 -- lr: 0.001 -- loss: 0.2764236629009247\n",
      "step_num: 1 -- epoch: 988 -- lr: 0.001 -- loss: 0.27630285173654556\n",
      "step_num: 1 -- epoch: 989 -- lr: 0.001 -- loss: 0.2762196436524391\n",
      "step_num: 1 -- epoch: 990 -- lr: 0.001 -- loss: 0.27609996497631073\n",
      "step_num: 1 -- epoch: 991 -- lr: 0.001 -- loss: 0.2759278044104576\n",
      "step_num: 1 -- epoch: 992 -- lr: 0.001 -- loss: 0.27606724947690964\n",
      "step_num: 1 -- epoch: 993 -- lr: 0.001 -- loss: 0.2758930027484894\n",
      "step_num: 1 -- epoch: 994 -- lr: 0.001 -- loss: 0.27587857842445374\n",
      "step_num: 1 -- epoch: 995 -- lr: 0.001 -- loss: 0.27605150640010834\n",
      "step_num: 1 -- epoch: 996 -- lr: 0.001 -- loss: 0.27593817561864853\n",
      "step_num: 1 -- epoch: 997 -- lr: 0.001 -- loss: 0.27600497007369995\n",
      "step_num: 1 -- epoch: 998 -- lr: 0.001 -- loss: 0.27588699758052826\n",
      "step_num: 1 -- epoch: 999 -- lr: 0.001 -- loss: 0.2757738530635834\n",
      "step_num: 1 -- epoch: 1000 -- lr: 0.001 -- loss: 0.27599794417619705\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0012363584 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00406*u_x0_y0*u_x1_y0 - 1.00785*u_x0_y1*v_x0_y0 + 0.0598026*u_x0_y2 + 0.0608336*u_x2_y0\n",
      "derivative of v:  -1.00745*u_x0_y0*v_x1_y0 - 1.00571*v_x0_y0*v_x0_y1 + 0.0595917*v_x0_y2 + 0.0604697*v_x2_y0\n",
      "step_num: 1 -- epoch: 1001 -- lr: 0.001 -- loss: 0.2824282795190811\n",
      "step_num: 1 -- epoch: 1002 -- lr: 0.001 -- loss: 0.27806617319583893\n",
      "step_num: 1 -- epoch: 1003 -- lr: 0.001 -- loss: 0.2760816290974617\n",
      "step_num: 1 -- epoch: 1004 -- lr: 0.001 -- loss: 0.27563731372356415\n",
      "step_num: 1 -- epoch: 1005 -- lr: 0.001 -- loss: 0.27560487389564514\n",
      "step_num: 1 -- epoch: 1006 -- lr: 0.001 -- loss: 0.274896577000618\n",
      "step_num: 1 -- epoch: 1007 -- lr: 0.001 -- loss: 0.27503763139247894\n",
      "step_num: 1 -- epoch: 1008 -- lr: 0.001 -- loss: 0.2750108316540718\n",
      "step_num: 1 -- epoch: 1009 -- lr: 0.001 -- loss: 0.2745988741517067\n",
      "step_num: 1 -- epoch: 1010 -- lr: 0.001 -- loss: 0.27449070662260056\n",
      "step_num: 1 -- epoch: 1011 -- lr: 0.001 -- loss: 0.27445847541093826\n",
      "step_num: 1 -- epoch: 1012 -- lr: 0.001 -- loss: 0.27439188957214355\n",
      "step_num: 1 -- epoch: 1013 -- lr: 0.001 -- loss: 0.27440741658210754\n",
      "step_num: 1 -- epoch: 1014 -- lr: 0.001 -- loss: 0.27428340911865234\n",
      "step_num: 1 -- epoch: 1015 -- lr: 0.001 -- loss: 0.274269163608551\n",
      "step_num: 1 -- epoch: 1016 -- lr: 0.001 -- loss: 0.27435971796512604\n",
      "step_num: 1 -- epoch: 1017 -- lr: 0.001 -- loss: 0.2742861807346344\n",
      "step_num: 1 -- epoch: 1018 -- lr: 0.001 -- loss: 0.2742476388812065\n",
      "step_num: 1 -- epoch: 1019 -- lr: 0.001 -- loss: 0.2744421139359474\n",
      "step_num: 1 -- epoch: 1020 -- lr: 0.001 -- loss: 0.27429595589637756\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1021 -- lr: 0.001 -- loss: 0.29836050420999527\n",
      "step_num: 1 -- epoch: 1022 -- lr: 0.001 -- loss: 0.29172515869140625\n",
      "step_num: 1 -- epoch: 1023 -- lr: 0.001 -- loss: 0.2867765352129936\n",
      "step_num: 1 -- epoch: 1024 -- lr: 0.001 -- loss: 0.2860649451613426\n",
      "step_num: 1 -- epoch: 1025 -- lr: 0.001 -- loss: 0.2840256914496422\n",
      "step_num: 1 -- epoch: 1026 -- lr: 0.001 -- loss: 0.2838863134384155\n",
      "step_num: 1 -- epoch: 1027 -- lr: 0.001 -- loss: 0.2837216183543205\n",
      "step_num: 1 -- epoch: 1028 -- lr: 0.001 -- loss: 0.28309138119220734\n",
      "step_num: 1 -- epoch: 1029 -- lr: 0.001 -- loss: 0.2828313335776329\n",
      "step_num: 1 -- epoch: 1030 -- lr: 0.001 -- loss: 0.2828645408153534\n",
      "step_num: 1 -- epoch: 1031 -- lr: 0.001 -- loss: 0.2827949598431587\n",
      "step_num: 1 -- epoch: 1032 -- lr: 0.001 -- loss: 0.28261586278676987\n",
      "step_num: 1 -- epoch: 1033 -- lr: 0.001 -- loss: 0.2824844494462013\n",
      "step_num: 1 -- epoch: 1034 -- lr: 0.001 -- loss: 0.2823214456439018\n",
      "step_num: 1 -- epoch: 1035 -- lr: 0.001 -- loss: 0.2824181392788887\n",
      "step_num: 1 -- epoch: 1036 -- lr: 0.001 -- loss: 0.2822161018848419\n",
      "step_num: 1 -- epoch: 1037 -- lr: 0.001 -- loss: 0.2822682857513428\n",
      "step_num: 1 -- epoch: 1038 -- lr: 0.001 -- loss: 0.28209953755140305\n",
      "step_num: 1 -- epoch: 1039 -- lr: 0.001 -- loss: 0.28237204253673553\n",
      "step_num: 1 -- epoch: 1040 -- lr: 0.001 -- loss: 0.28234515339136124\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1041 -- lr: 0.001 -- loss: 0.2861912325024605\n",
      "step_num: 1 -- epoch: 1042 -- lr: 0.001 -- loss: 0.28324107080698013\n",
      "step_num: 1 -- epoch: 1043 -- lr: 0.001 -- loss: 0.28211719542741776\n",
      "step_num: 1 -- epoch: 1044 -- lr: 0.001 -- loss: 0.2810135707259178\n",
      "step_num: 1 -- epoch: 1045 -- lr: 0.001 -- loss: 0.2804104760289192\n",
      "step_num: 1 -- epoch: 1046 -- lr: 0.001 -- loss: 0.28012946993112564\n",
      "step_num: 1 -- epoch: 1047 -- lr: 0.001 -- loss: 0.28071925789117813\n",
      "step_num: 1 -- epoch: 1048 -- lr: 0.001 -- loss: 0.28024304658174515\n",
      "step_num: 1 -- epoch: 1049 -- lr: 0.001 -- loss: 0.28003794699907303\n",
      "step_num: 1 -- epoch: 1050 -- lr: 0.001 -- loss: 0.2799956202507019\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0014680729 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00798*u_x0_y0*u_x1_y0 - 1.00751*u_x0_y1*v_x0_y0 + 0.0593385*u_x0_y2 + 0.0608336*u_x2_y0 - 0.0079284\n",
      "derivative of v:  -1.00488*u_x0_y0*v_x1_y0 - 1.00638*v_x0_y0*v_x0_y1 + 0.0607654*v_x0_y2 + 0.0592059*v_x2_y0\n",
      "step_num: 1 -- epoch: 1051 -- lr: 0.001 -- loss: 0.28001580387353897\n",
      "step_num: 1 -- epoch: 1052 -- lr: 0.001 -- loss: 0.27970875799655914\n",
      "step_num: 1 -- epoch: 1053 -- lr: 0.001 -- loss: 0.27965742349624634\n",
      "step_num: 1 -- epoch: 1054 -- lr: 0.001 -- loss: 0.2797163128852844\n",
      "step_num: 1 -- epoch: 1055 -- lr: 0.001 -- loss: 0.27968426793813705\n",
      "step_num: 1 -- epoch: 1056 -- lr: 0.001 -- loss: 0.279847614467144\n",
      "step_num: 1 -- epoch: 1057 -- lr: 0.001 -- loss: 0.2798066586256027\n",
      "step_num: 1 -- epoch: 1058 -- lr: 0.001 -- loss: 0.27993010729551315\n",
      "step_num: 1 -- epoch: 1059 -- lr: 0.001 -- loss: 0.2796994149684906\n",
      "step_num: 1 -- epoch: 1060 -- lr: 0.001 -- loss: 0.27968552708625793\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1061 -- lr: 0.001 -- loss: 0.30567023158073425\n",
      "step_num: 1 -- epoch: 1062 -- lr: 0.001 -- loss: 0.30426330864429474\n",
      "step_num: 1 -- epoch: 1063 -- lr: 0.001 -- loss: 0.29979830235242844\n",
      "step_num: 1 -- epoch: 1064 -- lr: 0.001 -- loss: 0.2990235984325409\n",
      "step_num: 1 -- epoch: 1065 -- lr: 0.001 -- loss: 0.29821208119392395\n",
      "step_num: 1 -- epoch: 1066 -- lr: 0.001 -- loss: 0.29815779626369476\n",
      "step_num: 1 -- epoch: 1067 -- lr: 0.001 -- loss: 0.2982706129550934\n",
      "step_num: 1 -- epoch: 1068 -- lr: 0.001 -- loss: 0.2977774366736412\n",
      "step_num: 1 -- epoch: 1069 -- lr: 0.001 -- loss: 0.2984031140804291\n",
      "step_num: 1 -- epoch: 1070 -- lr: 0.001 -- loss: 0.29773714393377304\n",
      "step_num: 1 -- epoch: 1071 -- lr: 0.001 -- loss: 0.29776010662317276\n",
      "step_num: 1 -- epoch: 1072 -- lr: 0.001 -- loss: 0.29764431715011597\n",
      "step_num: 1 -- epoch: 1073 -- lr: 0.001 -- loss: 0.2980591952800751\n",
      "step_num: 1 -- epoch: 1074 -- lr: 0.001 -- loss: 0.29760004580020905\n",
      "step_num: 1 -- epoch: 1075 -- lr: 0.001 -- loss: 0.29773835092782974\n",
      "step_num: 1 -- epoch: 1076 -- lr: 0.001 -- loss: 0.29748743027448654\n",
      "step_num: 1 -- epoch: 1077 -- lr: 0.001 -- loss: 0.2976900562644005\n",
      "step_num: 1 -- epoch: 1078 -- lr: 0.001 -- loss: 0.2973194718360901\n",
      "step_num: 1 -- epoch: 1079 -- lr: 0.001 -- loss: 0.2972201704978943\n",
      "step_num: 1 -- epoch: 1080 -- lr: 0.001 -- loss: 0.29723525792360306\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1081 -- lr: 0.001 -- loss: 0.29727740585803986\n",
      "step_num: 1 -- epoch: 1082 -- lr: 0.001 -- loss: 0.293029323220253\n",
      "step_num: 1 -- epoch: 1083 -- lr: 0.001 -- loss: 0.2898544371128082\n",
      "step_num: 1 -- epoch: 1084 -- lr: 0.001 -- loss: 0.2875833511352539\n",
      "step_num: 1 -- epoch: 1085 -- lr: 0.001 -- loss: 0.28768564760684967\n",
      "step_num: 1 -- epoch: 1086 -- lr: 0.001 -- loss: 0.2874523997306824\n",
      "step_num: 1 -- epoch: 1087 -- lr: 0.001 -- loss: 0.28745634108781815\n",
      "step_num: 1 -- epoch: 1088 -- lr: 0.001 -- loss: 0.28697669506073\n",
      "step_num: 1 -- epoch: 1089 -- lr: 0.001 -- loss: 0.2867787033319473\n",
      "step_num: 1 -- epoch: 1090 -- lr: 0.001 -- loss: 0.2865576893091202\n",
      "step_num: 1 -- epoch: 1091 -- lr: 0.001 -- loss: 0.28679950535297394\n",
      "step_num: 1 -- epoch: 1092 -- lr: 0.001 -- loss: 0.2866833657026291\n",
      "step_num: 1 -- epoch: 1093 -- lr: 0.001 -- loss: 0.28667791932821274\n",
      "step_num: 1 -- epoch: 1094 -- lr: 0.001 -- loss: 0.2864205911755562\n",
      "step_num: 1 -- epoch: 1095 -- lr: 0.001 -- loss: 0.2864755243062973\n",
      "step_num: 1 -- epoch: 1096 -- lr: 0.001 -- loss: 0.2864352613687515\n",
      "step_num: 1 -- epoch: 1097 -- lr: 0.001 -- loss: 0.2863517627120018\n",
      "step_num: 1 -- epoch: 1098 -- lr: 0.001 -- loss: 0.2865216061472893\n",
      "step_num: 1 -- epoch: 1099 -- lr: 0.001 -- loss: 0.2863185405731201\n",
      "step_num: 1 -- epoch: 1100 -- lr: 0.001 -- loss: 0.28675905615091324\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0013383101 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00761*u_x0_y0*u_x1_y0 - 0.00647988*u_x0_y0*u_x1_y1 - 1.00558*u_x0_y1*v_x0_y0 + 0.0578572*u_x0_y2 + 0.059368*u_x2_y0\n",
      "derivative of v:  -1.00645*u_x0_y0*v_x1_y0 - 1.00434*v_x0_y0*v_x0_y1 + 0.058827*v_x0_y2 + 0.058147*v_x2_y0\n",
      "step_num: 1 -- epoch: 1101 -- lr: 0.001 -- loss: 0.27826259285211563\n",
      "step_num: 1 -- epoch: 1102 -- lr: 0.001 -- loss: 0.2757670357823372\n",
      "step_num: 1 -- epoch: 1103 -- lr: 0.001 -- loss: 0.2735365554690361\n",
      "step_num: 1 -- epoch: 1104 -- lr: 0.001 -- loss: 0.2726219445466995\n",
      "step_num: 1 -- epoch: 1105 -- lr: 0.001 -- loss: 0.27208273857831955\n",
      "step_num: 1 -- epoch: 1106 -- lr: 0.001 -- loss: 0.2722395360469818\n",
      "step_num: 1 -- epoch: 1107 -- lr: 0.001 -- loss: 0.27201415598392487\n",
      "step_num: 1 -- epoch: 1108 -- lr: 0.001 -- loss: 0.27210715413093567\n",
      "step_num: 1 -- epoch: 1109 -- lr: 0.001 -- loss: 0.2720717042684555\n",
      "step_num: 1 -- epoch: 1110 -- lr: 0.001 -- loss: 0.2719859778881073\n",
      "step_num: 1 -- epoch: 1111 -- lr: 0.001 -- loss: 0.27185676991939545\n",
      "step_num: 1 -- epoch: 1112 -- lr: 0.001 -- loss: 0.2716765031218529\n",
      "step_num: 1 -- epoch: 1113 -- lr: 0.001 -- loss: 0.2716418579220772\n",
      "step_num: 1 -- epoch: 1114 -- lr: 0.001 -- loss: 0.27153461426496506\n",
      "step_num: 1 -- epoch: 1115 -- lr: 0.001 -- loss: 0.2716044634580612\n",
      "step_num: 1 -- epoch: 1116 -- lr: 0.001 -- loss: 0.2715955004096031\n",
      "step_num: 1 -- epoch: 1117 -- lr: 0.001 -- loss: 0.27157845348119736\n",
      "step_num: 1 -- epoch: 1118 -- lr: 0.001 -- loss: 0.2716129347681999\n",
      "step_num: 1 -- epoch: 1119 -- lr: 0.001 -- loss: 0.2716417461633682\n",
      "step_num: 1 -- epoch: 1120 -- lr: 0.001 -- loss: 0.2715175002813339\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1121 -- lr: 0.001 -- loss: 0.2797468900680542\n",
      "step_num: 1 -- epoch: 1122 -- lr: 0.001 -- loss: 0.27632585167884827\n",
      "step_num: 1 -- epoch: 1123 -- lr: 0.001 -- loss: 0.2746942937374115\n",
      "step_num: 1 -- epoch: 1124 -- lr: 0.001 -- loss: 0.2737768143415451\n",
      "step_num: 1 -- epoch: 1125 -- lr: 0.001 -- loss: 0.27297599613666534\n",
      "step_num: 1 -- epoch: 1126 -- lr: 0.001 -- loss: 0.27309132367372513\n",
      "step_num: 1 -- epoch: 1127 -- lr: 0.001 -- loss: 0.27292608469724655\n",
      "step_num: 1 -- epoch: 1128 -- lr: 0.001 -- loss: 0.2730541229248047\n",
      "step_num: 1 -- epoch: 1129 -- lr: 0.001 -- loss: 0.2727503255009651\n",
      "step_num: 1 -- epoch: 1130 -- lr: 0.001 -- loss: 0.2727752923965454\n",
      "step_num: 1 -- epoch: 1131 -- lr: 0.001 -- loss: 0.2725837901234627\n",
      "step_num: 1 -- epoch: 1132 -- lr: 0.001 -- loss: 0.27263616770505905\n",
      "step_num: 1 -- epoch: 1133 -- lr: 0.001 -- loss: 0.27270206063985825\n",
      "step_num: 1 -- epoch: 1134 -- lr: 0.001 -- loss: 0.272633820772171\n",
      "step_num: 1 -- epoch: 1135 -- lr: 0.001 -- loss: 0.2724386230111122\n",
      "step_num: 1 -- epoch: 1136 -- lr: 0.001 -- loss: 0.2724379748106003\n",
      "step_num: 1 -- epoch: 1137 -- lr: 0.001 -- loss: 0.27253513038158417\n",
      "step_num: 1 -- epoch: 1138 -- lr: 0.001 -- loss: 0.27251363545656204\n",
      "step_num: 1 -- epoch: 1139 -- lr: 0.001 -- loss: 0.2724381759762764\n",
      "step_num: 1 -- epoch: 1140 -- lr: 0.001 -- loss: 0.27234701812267303\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1141 -- lr: 0.001 -- loss: 0.283281646668911\n",
      "step_num: 1 -- epoch: 1142 -- lr: 0.001 -- loss: 0.27981071174144745\n",
      "step_num: 1 -- epoch: 1143 -- lr: 0.001 -- loss: 0.27747954428195953\n",
      "step_num: 1 -- epoch: 1144 -- lr: 0.001 -- loss: 0.27691975235939026\n",
      "step_num: 1 -- epoch: 1145 -- lr: 0.001 -- loss: 0.27705392241477966\n",
      "step_num: 1 -- epoch: 1146 -- lr: 0.001 -- loss: 0.2763436436653137\n",
      "step_num: 1 -- epoch: 1147 -- lr: 0.001 -- loss: 0.2761235162615776\n",
      "step_num: 1 -- epoch: 1148 -- lr: 0.001 -- loss: 0.27626778185367584\n",
      "step_num: 1 -- epoch: 1149 -- lr: 0.001 -- loss: 0.27601316571235657\n",
      "step_num: 1 -- epoch: 1150 -- lr: 0.001 -- loss: 0.27561336010694504\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0013394215 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.0086*u_x0_y0*u_x1_y0 - 1.00623*u_x0_y1*v_x0_y0 + 0.0592236*u_x0_y2 + 0.0589543*u_x2_y0\n",
      "derivative of v:  -1.00815*u_x0_y0*v_x1_y0 - 1.00721*v_x0_y0*v_x0_y1 + 0.0054256*v_x0_y0 + 0.0581113*v_x0_y2 + 0.0595319*v_x2_y0\n",
      "step_num: 1 -- epoch: 1151 -- lr: 0.001 -- loss: 0.27615825831890106\n",
      "step_num: 1 -- epoch: 1152 -- lr: 0.001 -- loss: 0.2755339816212654\n",
      "step_num: 1 -- epoch: 1153 -- lr: 0.001 -- loss: 0.27557333558797836\n",
      "step_num: 1 -- epoch: 1154 -- lr: 0.001 -- loss: 0.2757311463356018\n",
      "step_num: 1 -- epoch: 1155 -- lr: 0.001 -- loss: 0.27564216405153275\n",
      "step_num: 1 -- epoch: 1156 -- lr: 0.001 -- loss: 0.2753346636891365\n",
      "step_num: 1 -- epoch: 1157 -- lr: 0.001 -- loss: 0.27556396275758743\n",
      "step_num: 1 -- epoch: 1158 -- lr: 0.001 -- loss: 0.2754650190472603\n",
      "step_num: 1 -- epoch: 1159 -- lr: 0.001 -- loss: 0.2755048796534538\n",
      "step_num: 1 -- epoch: 1160 -- lr: 0.001 -- loss: 0.27555588632822037\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1161 -- lr: 0.001 -- loss: 0.29901421815156937\n",
      "step_num: 1 -- epoch: 1162 -- lr: 0.001 -- loss: 0.2957138940691948\n",
      "step_num: 1 -- epoch: 1163 -- lr: 0.001 -- loss: 0.2939123958349228\n",
      "step_num: 1 -- epoch: 1164 -- lr: 0.001 -- loss: 0.2930128201842308\n",
      "step_num: 1 -- epoch: 1165 -- lr: 0.001 -- loss: 0.29302849620580673\n",
      "step_num: 1 -- epoch: 1166 -- lr: 0.001 -- loss: 0.293306402862072\n",
      "step_num: 1 -- epoch: 1167 -- lr: 0.001 -- loss: 0.29296961426734924\n",
      "step_num: 1 -- epoch: 1168 -- lr: 0.001 -- loss: 0.2926720604300499\n",
      "step_num: 1 -- epoch: 1169 -- lr: 0.001 -- loss: 0.29250404238700867\n",
      "step_num: 1 -- epoch: 1170 -- lr: 0.001 -- loss: 0.2919834405183792\n",
      "step_num: 1 -- epoch: 1171 -- lr: 0.001 -- loss: 0.29217441380023956\n",
      "step_num: 1 -- epoch: 1172 -- lr: 0.001 -- loss: 0.29231473058462143\n",
      "step_num: 1 -- epoch: 1173 -- lr: 0.001 -- loss: 0.29208067804574966\n",
      "step_num: 1 -- epoch: 1174 -- lr: 0.001 -- loss: 0.291886530816555\n",
      "step_num: 1 -- epoch: 1175 -- lr: 0.001 -- loss: 0.29191430658102036\n",
      "step_num: 1 -- epoch: 1176 -- lr: 0.001 -- loss: 0.29240427166223526\n",
      "step_num: 1 -- epoch: 1177 -- lr: 0.001 -- loss: 0.29195109009742737\n",
      "step_num: 1 -- epoch: 1178 -- lr: 0.001 -- loss: 0.2921162545681\n",
      "step_num: 1 -- epoch: 1179 -- lr: 0.001 -- loss: 0.29177873581647873\n",
      "step_num: 1 -- epoch: 1180 -- lr: 0.001 -- loss: 0.2917342633008957\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "step_num: 1 -- epoch: 1181 -- lr: 0.001 -- loss: 0.28358108550310135\n",
      "step_num: 1 -- epoch: 1182 -- lr: 0.001 -- loss: 0.28250085562467575\n",
      "step_num: 1 -- epoch: 1183 -- lr: 0.001 -- loss: 0.2809932604432106\n",
      "step_num: 1 -- epoch: 1184 -- lr: 0.001 -- loss: 0.2806916832923889\n",
      "step_num: 1 -- epoch: 1185 -- lr: 0.001 -- loss: 0.2807116433978081\n",
      "step_num: 1 -- epoch: 1186 -- lr: 0.001 -- loss: 0.2803919017314911\n",
      "step_num: 1 -- epoch: 1187 -- lr: 0.001 -- loss: 0.280282124876976\n",
      "step_num: 1 -- epoch: 1188 -- lr: 0.001 -- loss: 0.28015947341918945\n",
      "step_num: 1 -- epoch: 1189 -- lr: 0.001 -- loss: 0.28011632710695267\n",
      "step_num: 1 -- epoch: 1190 -- lr: 0.001 -- loss: 0.28042663633823395\n",
      "step_num: 1 -- epoch: 1191 -- lr: 0.001 -- loss: 0.28036170452833176\n",
      "step_num: 1 -- epoch: 1192 -- lr: 0.001 -- loss: 0.28023022413253784\n",
      "step_num: 1 -- epoch: 1193 -- lr: 0.001 -- loss: 0.2806704640388489\n",
      "step_num: 1 -- epoch: 1194 -- lr: 0.001 -- loss: 0.2801123112440109\n",
      "step_num: 1 -- epoch: 1195 -- lr: 0.001 -- loss: 0.28051937371492386\n",
      "step_num: 1 -- epoch: 1196 -- lr: 0.001 -- loss: 0.2802229970693588\n",
      "step_num: 1 -- epoch: 1197 -- lr: 0.001 -- loss: 0.2805396616458893\n",
      "step_num: 1 -- epoch: 1198 -- lr: 0.001 -- loss: 0.280233658850193\n",
      "step_num: 1 -- epoch: 1199 -- lr: 0.001 -- loss: 0.2800445109605789\n",
      "step_num: 1 -- epoch: 1200 -- lr: 0.001 -- loss: 0.2805286571383476\n",
      "generating data ...\n",
      "step 20 generated.\n",
      "generated.\n",
      "generating data ...\n",
      "generated.\n",
      "=============== Max evaluate error: 0.0013900916 ===============\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00585*u_x0_y0*u_x1_y0 - 1.00535*u_x0_y1*v_x0_y0 + 0.0604929*u_x0_y2 + 0.0596764*u_x2_y0\n",
      "derivative of v:  -1.00689*u_x0_y0*v_x1_y0 - 1.00612*v_x0_y0*v_x0_y1 + 0.0616746*v_x0_y2 + 0.0588492*v_x2_y0\n",
      "=============== Current Expression ===============\n",
      "derivative of u:  -1.00585*u_x0_y0*u_x1_y0 - 1.00535*u_x0_y1*v_x0_y0 + 0.0604929*u_x0_y2 + 0.0596764*u_x2_y0\n",
      "derivative of v:  -1.00689*u_x0_y0*v_x1_y0 - 1.00612*v_x0_y0*v_x0_y1 + 0.0616746*v_x0_y2 + 0.0588492*v_x2_y0\n",
      "======================= k_x0_y0 =======================: \n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "=========================================================\n",
      "======================= k_x0_y1 =======================: \n",
      "[[ 0.          0.          0.08333334  0.          0.        ]\n",
      " [ 0.          0.         -0.6666667   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.6666667   0.          0.        ]\n",
      " [ 0.          0.         -0.08333334  0.          0.        ]]\n",
      "=========================================================\n",
      "======================= k_x1_y0 =======================: \n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.08333334 -0.6666667   0.          0.6666667  -0.08333334]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "=========================================================\n",
      "======================= k_x0_y2 =======================: \n",
      "[[ 0.          0.         -0.08333334  0.          0.        ]\n",
      " [ 0.          0.          1.3333334   0.          0.        ]\n",
      " [ 0.          0.         -2.5         0.          0.        ]\n",
      " [ 0.          0.          1.3333334   0.          0.        ]\n",
      " [ 0.          0.         -0.08333334  0.          0.        ]]\n",
      "=========================================================\n",
      "======================= k_x1_y1 =======================: \n",
      "[[ 0.00694444 -0.05555556  0.          0.05555556 -0.00694444]\n",
      " [-0.05555556  0.44444448  0.         -0.44444448  0.05555556]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.05555556 -0.44444448  0.          0.44444448 -0.05555556]\n",
      " [-0.00694444  0.05555556  0.         -0.05555556  0.00694444]]\n",
      "=========================================================\n",
      "======================= k_x2_y0 =======================: \n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [-0.08333334  1.3333334  -2.5         1.3333334  -0.08333334]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "pretrain(config=my_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-09T04:46:15.268835200Z",
     "start_time": "2023-09-09T02:47:55.764983500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
