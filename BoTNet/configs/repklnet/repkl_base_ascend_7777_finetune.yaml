# system
# mpirun --allow-run-as-root -n 8 python train.py --config ./configs/repklnet/repkl_base_ascend_7777_finetune.yaml --data_dir ../imagenet --ckpt_path
mode: 0
distribute: True
num_parallel_workers: 32
val_while_train: True
val_interval: 1

# dataset
dataset: "imagenet"
data_dir: "/path/to/imagenet"
shuffle: True
dataset_download: False
batch_size: 32
drop_remainder: True

# augmentation
image_resize: 384
scale: [ 0.08, 1.0 ]
ratio: [ 0.75, 1.333 ]
hflip: 0.5
interpolation: "bicubic"
re_prob: 0.
mixup: 0.
cutmix: 0.
cutmix_prob: 0.
crop_pct: 1.
color_jitter: [ 0.4, 0.4, 0.4 ]
auto_augment: "randaug-m9-mstd0.5"

# model
model: "replknet31_base_7777"
num_classes: 1000
pretrained: False
ckpt_path: ""
keep_checkpoint_max: 10
ckpt_save_policy: "top_k"
ckpt_save_dir: "./ckpt_384"
epoch_size: 30
dataset_sink_mode: True
amp_level: "O2"

# loss
loss: "CE"
loss_scale: 65536.0
label_smoothing: 0.1

# lr scheduler
scheduler: "cosine_decay"
lr: 0.0001
min_lr: 1e-6
warmup_epochs: 1
decay_epochs: 29
lr_epoch_stair: False

# optimizer
opt: "adamw"
weight_decay: 0.00000001
filter_bias_and_bn: True
use_nesterov: False
loss_scale_type: dynamic
drop_overflow_update: True

# train
clip_grad: True
clip_value: 5.
drop_path_rate: 0.8
layer_decay: 0.7